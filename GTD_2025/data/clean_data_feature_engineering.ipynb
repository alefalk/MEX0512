{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to download GTD data, too large for github. Place it in this folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181691, 135)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'gtd.csv'\n",
    "data = pd.read_csv(data_path, encoding='ISO-8859-1')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98343, 135)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['gname'] != 'Unknown']\n",
    "data = data.loc[(data['iyear'] != 0) & (data['imonth'] != 0) & (data['iday'] != 0)]\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87500, 135)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[data['weaptype1_txt'] != 'Unknown']\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "77923\n",
      "85982\n",
      "87438\n"
     ]
    }
   ],
   "source": [
    "print(data['weaptype1_txt'].isnull().sum())\n",
    "print(data['weaptype2_txt'].isnull().sum())\n",
    "print(data['weaptype3_txt'].isnull().sum())\n",
    "print(data['weaptype4_txt'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many missing values in weapon types other than 1, we should drop these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "\n",
    "#data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87500, 46)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold = len(data) * 0.9  # Keep columns with at least 70% non-NaN\n",
    "data_cleaned = data.dropna(axis=1, thresh=threshold)\n",
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.drop(columns=['crit1', 'crit2', 'crit3', 'doubtterr', 'eventid', 'attacktype1_txt', 'targtype1_txt', 'targsubtype1_txt', 'natlty1_txt', 'weaptype1_txt', 'weapsubtype1_txt', 'INT_LOG', 'INT_IDEO', 'INT_MISC', 'INT_ANY', 'country_txt', 'region_txt', 'guncertain1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87500, 28)\n"
     ]
    }
   ],
   "source": [
    "print(data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iyear              0\n",
       "imonth             0\n",
       "iday               0\n",
       "extended           0\n",
       "country            0\n",
       "region             0\n",
       "provstate        157\n",
       "city              75\n",
       "latitude        2621\n",
       "longitude       2621\n",
       "specificity        3\n",
       "vicinity           0\n",
       "multiple           1\n",
       "success            0\n",
       "suicide            0\n",
       "attacktype1        0\n",
       "targtype1          0\n",
       "targsubtype1    3771\n",
       "target1          356\n",
       "natlty1          549\n",
       "gname              0\n",
       "individual         0\n",
       "weaptype1          0\n",
       "weapsubtype1    3341\n",
       "nkill           5271\n",
       "property           0\n",
       "ishostkid        142\n",
       "dbsource           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.dropna(subset=['latitude', 'longitude', 'provstate', 'city', 'multiple','target1','natlty1', 'ishostkid'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iyear              0\n",
       "imonth             0\n",
       "iday               0\n",
       "extended           0\n",
       "country            0\n",
       "region             0\n",
       "provstate          0\n",
       "city               0\n",
       "latitude           0\n",
       "longitude          0\n",
       "specificity        0\n",
       "vicinity           0\n",
       "multiple           0\n",
       "success            0\n",
       "suicide            0\n",
       "attacktype1        0\n",
       "targtype1          0\n",
       "targsubtype1    3188\n",
       "target1            0\n",
       "natlty1            0\n",
       "gname              0\n",
       "individual         0\n",
       "weaptype1          0\n",
       "weapsubtype1    3169\n",
       "nkill           4892\n",
       "property           0\n",
       "ishostkid          0\n",
       "dbsource           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned = data_cleaned.drop(columns=['targsubtype1', 'weapsubtype1', 'dbsource'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iyear             0\n",
       "imonth            0\n",
       "iday              0\n",
       "extended          0\n",
       "country           0\n",
       "region            0\n",
       "provstate         0\n",
       "city              0\n",
       "latitude          0\n",
       "longitude         0\n",
       "specificity       0\n",
       "vicinity          0\n",
       "multiple          0\n",
       "success           0\n",
       "suicide           0\n",
       "attacktype1       0\n",
       "targtype1         0\n",
       "target1           0\n",
       "natlty1           0\n",
       "gname             0\n",
       "individual        0\n",
       "weaptype1         0\n",
       "nkill          4892\n",
       "property          0\n",
       "ishostkid         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned['nkill'] = data_cleaned['nkill'].fillna(data_cleaned['nkill'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83654, 25)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cleaned.to_csv('cleaned_gtd.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition1 = data_cleaned[data_cleaned['iyear'] <= 1980]\n",
    "groups = partition1.groupby(['iyear', 'gname']).size().reset_index(name='count')\n",
    "top5 = groups.groupby('gname')['count'].sum().nlargest(5).index\n",
    "partition1 = data_cleaned[data_cleaned['iyear'] <= 1979]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gname\n",
       "Irish Republican Army (IRA)     987\n",
       "Protestant extremists           198\n",
       "Ulster Volunteer Force (UVF)    167\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition1 = partition1[partition1['gname'].isin(top5)]\n",
    "partition1 = partition1[partition1['gname'] != 'Palestinians']\n",
    "partition1 = partition1[partition1['gname'] != 'Basque Fatherland and Freedom (ETA)']\n",
    "\n",
    "partition1['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "783"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainp1 = partition1[(partition1['iyear'] <= 1975)]\n",
    "len(trainp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp1 = partition1[(partition1['iyear'] > 1975)]\n",
    "len(testp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gname\n",
      "Irish Republican Army (IRA)     0.713018\n",
      "Protestant extremists           0.153846\n",
      "Ulster Volunteer Force (UVF)    0.133136\n",
      "Name: proportion, dtype: float64\n",
      "338\n"
     ]
    }
   ],
   "source": [
    "# Assuming your test set is called 'test_df'\n",
    "eta_ira_df = testp1[testp1['gname'].isin(['Irish Republican Army (IRA)'])]\n",
    "non_eta_ira_df = testp1[~testp1['gname'].isin(['Irish Republican Army (IRA)'])]\n",
    "\n",
    "# Determine how much to downscale (e.g., keep 50% of the original)\n",
    "downscale_factor = 0.35  # Adjust as needed\n",
    "target_size = int(len(eta_ira_df) * downscale_factor)\n",
    "\n",
    "# Stratified sampling based on key feature distributions\n",
    "sampled_eta_ira_df = eta_ira_df.groupby(['weaptype1', 'attacktype1', 'city'], group_keys=False).apply(\n",
    "    lambda x: x.sample(frac=downscale_factor, random_state=42) if len(x) > 1 else x\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Combine the reduced ETA/IRA data with the rest of the test set\n",
    "downscaled_test_df = pd.concat([non_eta_ira_df, sampled_eta_ira_df], ignore_index=True)\n",
    "\n",
    "# Verify new class distribution\n",
    "print(downscaled_test_df['gname'].value_counts(normalize=True))  # Check proportion\n",
    "print(len(downscaled_test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3015165031222123\n"
     ]
    }
   ],
   "source": [
    "print(len(downscaled_test_df) / (len(trainp1) + len(downscaled_test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gname\n",
      "Irish Republican Army (IRA)     241\n",
      "Protestant extremists            52\n",
      "Ulster Volunteer Force (UVF)     45\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gname\n",
       "Irish Republican Army (IRA)     515\n",
       "Protestant extremists           146\n",
       "Ulster Volunteer Force (UVF)    122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testp1 = downscaled_test_df\n",
    "print(downscaled_test_df['gname'].value_counts())\n",
    "trainp1['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "testp1 = downscaled_test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_factorize(df, text_features):\n",
    "    mappings = {}\n",
    "    for col in text_features:\n",
    "        df[col], uniques = pd.factorize(df[col])\n",
    "        mappings[col] = uniques\n",
    "    return df, mappings\n",
    "\n",
    "def apply_factorize(df, mappings):\n",
    "    for col, uniques in mappings.items():\n",
    "        df[col] = df[col].apply(lambda x: uniques.get_loc(x) if x in uniques else -1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = trainp1.select_dtypes(include='object').columns\n",
    "\n",
    "trainp1, gname_mappings = fit_factorize(trainp1, text_features)\n",
    "testp1 = apply_factorize(testp1, gname_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gname\n",
       "0    515\n",
       "2    146\n",
       "1    122\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainp1['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gname\n",
       "0    241\n",
       "2     52\n",
       "1     45\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testp1['gname'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainp1.to_csv('../Codes/CleanPartitions/trainp1.csv', index=False)\n",
    "testp1.to_csv('../Codes/CleanPartitions/testp1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Shining Path (SL)', 'Farabundo Marti National Liberation Front (FMLN)',\n",
       "       'Irish Republican Army (IRA)', 'Basque Fatherland and Freedom (ETA)'],\n",
       "      dtype='object', name='gname')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition2 = data_cleaned[(data_cleaned['iyear'] >= 1980) & (data_cleaned['iyear'] <= 1995)]\n",
    "partition2['attack_date'] = pd.to_datetime({'year': partition2['iyear'], 'month': partition2['imonth'], 'day': partition2['iday']})\n",
    "\n",
    "groups = partition2.groupby(['iyear', 'gname']).size().reset_index(name='count')\n",
    "top5 = groups.groupby('gname')['count'].sum().nlargest(4).index\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition2 = partition2[partition2['gname'].isin(top5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6645"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainsizep2 = int(0.7 * len(partition2))\n",
    "trainsizep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1989-09-05 00:00:00\n"
     ]
    }
   ],
   "source": [
    "print(partition2.iloc[trainsizep2]['attack_date'])  # If train_size is an integer position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatep2 = '1989-09-05'\n",
    "trainp2 = partition2[partition2['attack_date'] <= traindatep2]\n",
    "testp2 = partition2[partition2['attack_date'] > traindatep2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train %:  0.7001263956182853\n",
      "Test %:  0.2998736043817148\n"
     ]
    }
   ],
   "source": [
    "print('Train %: ', len(trainp2)/len(partition2))\n",
    "print('Test %: ', len(testp2)/len(partition2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = trainp2.select_dtypes(include='object').columns\n",
    "\n",
    "trainp2, gname_mappings = fit_factorize(trainp2, text_features)\n",
    "testp2 = apply_factorize(testp2, gname_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainp2.to_csv('../Codes/CleanPartitions/trainp2.csv', index=False)\n",
    "testp2.to_csv('../Codes/CleanPartitions/testp2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Taliban', 'Communist Party of India - Maoist (CPI-Maoist)',\n",
       "       'Revolutionary Armed Forces of Colombia (FARC)',\n",
       "       'Liberation Tigers of Tamil Eelam (LTTE)',\n",
       "       'Tehrik-i-Taliban Pakistan (TTP)'],\n",
       "      dtype='object', name='gname')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition3 = data_cleaned[(data_cleaned['iyear'] >= 1996) & (data_cleaned['iyear'] <= 2010)]\n",
    "partition3['attack_date'] = pd.to_datetime({'year': partition3['iyear'], 'month': partition3['imonth'], 'day': partition3['iday']})\n",
    "\n",
    "groups = partition3.groupby(['iyear', 'gname']).size().reset_index(name='count')\n",
    "top5 = groups.groupby('gname')['count'].sum().nlargest(5).index\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition3 = partition3[partition3['gname'].isin(top5)]\n",
    "partition3 = partition3[partition3['gname'] != 'Communist Party of India - Maoist (CPI-Maoist)']\n",
    "partition3 = partition3[partition3['gname'] != 'Taliban']\n",
    "partition3 = partition3[partition3['gname'] != 'Tehrik-i-Taliban Pakistan (TTP)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2007-05-12 00:00:00\n"
     ]
    }
   ],
   "source": [
    "trainsizep3 = int(0.7 * len(partition3))\n",
    "print(partition3.iloc[trainsizep3]['attack_date'])  # If train_size is an integer position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatep3 = '2007-05-12'\n",
    "trainp3 = partition3[partition3['attack_date'] <= traindatep3]\n",
    "testp3 = partition3[partition3['attack_date'] > traindatep3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train %:  0.7012557832121613\n",
      "Test %:  0.29874421678783875\n"
     ]
    }
   ],
   "source": [
    "print('Train %: ', len(trainp3)/len(partition3))\n",
    "print('Test %: ', len(testp3)/len(partition3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = trainp3.select_dtypes(include='object').columns\n",
    "\n",
    "trainp3, gname_mappings = fit_factorize(trainp3, text_features)\n",
    "testp3 = apply_factorize(testp3, gname_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainp3.to_csv('../Codes/CleanPartitions/trainp3.csv', index=False)\n",
    "testp3.to_csv('../Codes/CleanPartitions/testp3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partition 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Taliban', 'Al-Shabaab', 'Boko Haram', 'New People's Army (NPA)'], dtype='object', name='gname')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition4 = data_cleaned[data_cleaned['iyear'] > 2010]\n",
    "partition4['attack_date'] = pd.to_datetime({'year': data_cleaned['iyear'], 'month': data_cleaned['imonth'], 'day': data_cleaned['iday']})\n",
    "groups = partition4.groupby(['iyear', 'gname']).size().reset_index(name='count')\n",
    "top5 = groups.groupby('gname')['count'].sum().nlargest(5).index\n",
    "top5 = top5.delete(1)\n",
    "top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition4 = partition4[partition4['gname'].isin(top5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gname\n",
      "Taliban                    0.314552\n",
      "Al-Shabaab                 0.240647\n",
      "Boko Haram                 0.239426\n",
      "New People's Army (NPA)    0.205375\n",
      "Name: proportion, dtype: float64\n",
      "Total after downscaling:  6549\n"
     ]
    }
   ],
   "source": [
    "def downscaling(dataframe, group, downscale_factor):\n",
    "    # Assuming your test set is called 'test_df'\n",
    "    eta_ira_df = dataframe[dataframe['gname'].isin([group])]\n",
    "    non_eta_ira_df = dataframe[~dataframe['gname'].isin([group])]\n",
    "\n",
    "    # Determine how much to downscale (e.g., keep 50% of the original)\n",
    "    #downscale_factor = 0.25  # Adjust as needed\n",
    "    target_size = int(len(eta_ira_df) * downscale_factor)\n",
    "\n",
    "    # Stratified sampling based on key feature distributions\n",
    "    sampled_eta_ira_df = eta_ira_df.groupby(['weaptype1', 'attacktype1', 'city'], group_keys=False).apply(\n",
    "        lambda x: x.sample(frac=downscale_factor, random_state=42) if len(x) > 1 else x\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    # Combine the reduced ETA/IRA data with the rest of the test set\n",
    "    downscaled_test_df = pd.concat([non_eta_ira_df, sampled_eta_ira_df], ignore_index=True)\n",
    "\n",
    "    # Verify new class distribution\n",
    "    #print(downscaled_test_df['gname'].value_counts(normalize=True))  # Check proportion\n",
    "    #print(len(downscaled_test_df[downscaled_test_df['gname']==group]))\n",
    "    #print(counts(downscaled_test_df, top5))\n",
    "    return downscaled_test_df\n",
    "\n",
    "downscaled_df = downscaling(partition4, 'Taliban', 0.15)\n",
    "downscaled_df_2 = downscaling(downscaled_df, 'Boko Haram', 0.55)\n",
    "downscaled_df_3 = downscaling(downscaled_df_2, 'Al-Shabaab', 0.5)\n",
    "\n",
    "print(downscaled_df_3['gname'].value_counts(normalize=True))  # Check proportion\n",
    "#print(len(downscaled_df_3[downscaled_df_3['gname']==group]))\n",
    "#total = counts(downscaled_df_3, top5)\n",
    "print('Total after downscaling: ', len(downscaled_df_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition4 = downscaled_df_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016-01-30 00:00:00\n"
     ]
    }
   ],
   "source": [
    "partition4['attack_date'] = pd.to_datetime(partition4['attack_date'])\n",
    "partition4 = partition4.sort_values(by='attack_date')\n",
    "trainsizep4 = int(0.7 * len(partition4))\n",
    "traindatep4 = partition4.iloc[trainsizep4]['attack_date']\n",
    "print(traindatep4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainp4 = partition4[partition4['attack_date'] <= '2016-01-30']\n",
    "testp4 = partition4[partition4['attack_date'] > '2016-01-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001068865475645\n",
      "0.29989311345243547\n"
     ]
    }
   ],
   "source": [
    "print(len(trainp4) / len(partition4))\n",
    "print(len(testp4) / len(partition4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = trainp4.select_dtypes(include='object').columns\n",
    "\n",
    "trainp4, gname_mappings = fit_factorize(trainp4, text_features)\n",
    "testp4 = apply_factorize(testp4, gname_mappings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainp4.to_csv('../Codes/CleanPartitions/trainp4.csv', index=False)\n",
    "testp4.to_csv('../Codes/CleanPartitions/testp4.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
