{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece52efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cd7832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../cleaned_gtd.csv'\n",
    "data_cleaned = pd.read_csv(path, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d597bc",
   "metadata": {},
   "source": [
    "### Group by attack date and perpetrators before splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9638e898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
       "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
       "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
       "       'gname', 'individual', 'weaptype1', 'nkill', 'property', 'ishostkid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned['attack_date'] = pd.to_datetime({'year': data_cleaned['iyear'], 'month': data_cleaned['imonth'], 'day': data_cleaned['iday']})\n",
    "data_cleaned.sort_values(by=['gname', 'attack_date'], inplace=True)\n",
    "data_cleaned = data_cleaned.drop(columns=['attack_date'])\n",
    "data_cleaned.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26e708ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates train and test data, first 70% of each group is added to train and remaining 30% to test\n",
    "def handle_leakage(df):\n",
    "    train_frames = []\n",
    "    test_frames = []\n",
    "\n",
    "    #first 70% of each groups attacks to training set, remainin 30% to testing set\n",
    "    for _, group_data in df.groupby('gname'):\n",
    "        split_point = int(len(group_data) * 0.7)  # 70% for training\n",
    "        train_frames.append(group_data.iloc[:split_point])\n",
    "        test_frames.append(group_data.iloc[split_point:])           \n",
    "\n",
    "\n",
    "    # Concatenate all the group-specific splits into final train and test DataFrames\n",
    "    train_df = pd.concat(train_frames)\n",
    "    test_df = pd.concat(test_frames)\n",
    "\n",
    "    # Shuffle each DataFrame separately\n",
    "    train_df = shuffle(train_df)\n",
    "    test_df = shuffle(test_df)\n",
    "\n",
    "    print(len(train_df))\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a73c31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100\n",
      "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
      "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
      "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
      "       'individual', 'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
      "      dtype='object')\n",
      "Combined  3000\n",
      "train + test  3000\n",
      "4200\n",
      "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
      "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
      "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
      "       'individual', 'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
      "      dtype='object')\n",
      "Combined  6000\n",
      "train + test  6000\n",
      "6300\n",
      "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
      "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
      "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
      "       'individual', 'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
      "      dtype='object')\n",
      "Combined  9000\n",
      "train + test  9000\n",
      "10020\n",
      "Index(['iyear', 'imonth', 'iday', 'extended', 'country', 'region', 'provstate',\n",
      "       'city', 'latitude', 'longitude', 'specificity', 'vicinity', 'multiple',\n",
      "       'success', 'suicide', 'attacktype1', 'targtype1', 'target1', 'natlty1',\n",
      "       'individual', 'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
      "      dtype='object')\n",
      "Combined  14340\n",
      "train + test  14340\n"
     ]
    }
   ],
   "source": [
    "sample_sizes = [100, 200, 300, 478]\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    # extract top 30 groups and sample \n",
    "    top_30_classes = data_cleaned['gname'].value_counts().head(30).index\n",
    "    top_30_df = data_cleaned[data_cleaned['gname'].isin(top_30_classes)]\n",
    "    top_30_df = top_30_df.groupby('gname').sample(n=sample_size, random_state=42)\n",
    "\n",
    "    features = top_30_df.drop(columns=['gname'])\n",
    "    labels = top_30_df['gname']\n",
    "\n",
    "    # greedy integer encoding of features\n",
    "    for col in features.select_dtypes(include='object').columns:\n",
    "        features[col], _ = pd.factorize(features[col])\n",
    "\n",
    "    top_30_encoded = pd.concat([features, labels], axis = 1)\n",
    "\n",
    "    #train test split\n",
    "    train, test = handle_leakage(top_30_encoded)\n",
    "    print(train.columns)\n",
    "    \n",
    "\n",
    "    combined = pd.concat([train, test])\n",
    "    print('Combined ', len(combined))\n",
    "    print('train + test ', len(train) + len(test))\n",
    "    #save to csv\n",
    "    combined.to_csv(f'engineered_dfs/df_top30_{sample_size}.csv')\n",
    "    train.to_csv(f'traindata/train{sample_size}.csv')\n",
    "    test.to_csv(f'testdata/test{sample_size}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
