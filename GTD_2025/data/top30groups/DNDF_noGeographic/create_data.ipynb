{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d100f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4523e56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"train\"):\n",
    "    os.mkdir(\"train\")\n",
    "if not os.path.isdir(\"test\"):\n",
    "    os.mkdir(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c71c4309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeData(traindata, testdata):\n",
    "\n",
    "    feature_columns = [col for col in traindata.columns if col != \"gname\"]\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_train = scaler.fit_transform(traindata[feature_columns])\n",
    "    X_scaled_test = scaler.transform(testdata[feature_columns])\n",
    "    traindata[feature_columns] = X_scaled_train\n",
    "    testdata[feature_columns] = X_scaled_test\n",
    "\n",
    "    #y_train = traindata['gname']\n",
    "    #y_test = testdata['gname']\n",
    "\n",
    "    #X_train = traindata.drop(columns=['gname'])\n",
    "    #X_test = testdata.drop(columns=['gname'])\n",
    "\n",
    "    #scaler = StandardScaler()\n",
    "    #X_train_scaled = scaler.fit_transform(X_train)\n",
    "    #X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    #X_train = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=traindata.index)\n",
    "    #X_test = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=testdata.index)\n",
    "\n",
    "    #traindata = pd.concat([X_train, y_train], axis=1)\n",
    "    #testdata = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    return traindata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b17068d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size train: 2100, Shape train: (2100, 14)\n",
      "Size test: 900, Shape test: (900, 14)\n",
      "Size train: 4200, Shape train: (4200, 14)\n",
      "Size test: 1800, Shape test: (1800, 14)\n",
      "Size train: 6300, Shape train: (6300, 14)\n",
      "Size test: 2700, Shape test: (2700, 14)\n",
      "Size train: 10020, Shape train: (10020, 14)\n",
      "Size test: 4320, Shape test: (4320, 14)\n"
     ]
    }
   ],
   "source": [
    "trainpath = '../traindata'\n",
    "testpath = '../testdata'\n",
    "\n",
    "partitions = [100, 200, 300, 478]\n",
    "\n",
    "for partition in partitions:\n",
    "    traindata = pd.read_csv(f'{trainpath}/train{partition}.csv',  encoding='ISO-8859-1')\n",
    "    testdata = pd.read_csv(f'{testpath}/test{partition}.csv',  encoding='ISO-8859-1')\n",
    "\n",
    "    traindata = traindata.drop(columns=['Unnamed: 0', 'country', 'city', 'region', 'provstate', 'latitude', 'longitude', 'natlty1', 'specificity', 'iyear', 'imonth', 'iday'])\n",
    "    testdata = testdata.drop(columns=['Unnamed: 0', 'country', 'city', 'region', 'provstate', 'latitude', 'longitude', 'natlty1', 'specificity', 'iyear', 'imonth', 'iday'])\n",
    "\n",
    "    traindata, testdata = normalizeData(traindata, testdata)\n",
    "\n",
    "    print(f'Size train: {len(traindata)}, Shape train: {traindata.shape}')\n",
    "    print(f'Size test: {len(testdata)}, Shape test: {testdata.shape}')\n",
    "    \n",
    "    traindata.to_csv(f'train/train{partition}.csv')\n",
    "    traindata.to_csv(f'test/test{partition}.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
