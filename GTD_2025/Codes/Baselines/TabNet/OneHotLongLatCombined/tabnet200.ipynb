{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Using cached pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.5.0)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (4.66.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "Using cached pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pytorch-tabnet\n",
      "Successfully installed pytorch-tabnet-4.1.0\n",
      "\n",
<<<<<<< HEAD
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1\u001b[0m\n",
=======
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pytorch-tabnet --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../../data/top30groups/DNDF_OneHotLongLatCombined/train/train{partition}.csv'\n",
    "testpath = f'../../../../data/top30groups/DNDF_OneHotLongLatCombined/test/test{partition}.csv'\n",
    "\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def split_data(dftrain, dftest):\n",
    "    Xtrain = dftrain.drop(columns=['gname']).values.astype(float)\n",
    "    Ytrain = dftrain['gname'].values\n",
    "    Xtest = dftest.drop(columns=['gname']).values.astype(float)\n",
    "    Ytest = dftest['gname'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    Ytrain = le.fit_transform(Ytrain)\n",
    "    Ytest = le.transform(Ytest)\n",
    "\n",
<<<<<<< HEAD
    "    #y_pred_decoded = model.label_encoder.inverse_transform(y_pred)\n",
    "    y_true_decoded = le.inverse_transform(Ytest)\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, y_true_decoded, le\n",
=======
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 8,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch_tabnet.sklearn import TabNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "\n",
    "def find_best_tabnet(Xtrain, Ytrain, n_iter=20):\n",
    "    print(\"Starting TabNet grid search\")\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    model = TabNetClassifier(verbose=0, seed=42)\n",
    "\n",
    "    param_dist = {\n",
    "        'n_d': [8, 16, 24],\n",
    "        'n_a': [8, 16, 24],\n",
    "        'n_steps': [3, 4, 5],\n",
    "        'gamma': [1.0, 1.3, 1.5],\n",
    "        'lambda_sparse': [1e-4, 1e-3, 1e-2],\n",
    "        'optimizer_params': [{'lr': 0.01}]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
<<<<<<< HEAD
    "    fit_params = {\n",
    "    'max_epochs': 100,        # adjust as needed\n",
    "    'batch_size': 64,        # lower if you get CUDA OOM\n",
    "    'virtual_batch_size': 16, # smaller \"sub-batches\" to reduce memory usage\n",
    "    'patience': 10,\n",
    "    'drop_last': False\n",
    "}\n",
    "\n",
    "    random_search.fit(Xtrain, Ytrain, **fit_params)\n",
=======
    "    random_search.fit(Xtrain, Ytrain)\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best accuracy:\", random_search.best_score_)\n",
    "\n",
    "    return random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
=======
   "execution_count": 9,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TabNet grid search\n",
      "CUDA available: True\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 24, 'n_a': 24, 'lambda_sparse': 0.0001, 'gamma': 1.0}\n",
      "Best accuracy: 0.47190476190476194\n",
      "epoch 0  | loss: 3.79452 |  0:00:03s\n",
      "epoch 1  | loss: 3.43537 |  0:00:06s\n",
      "epoch 2  | loss: 3.22375 |  0:00:10s\n",
      "epoch 3  | loss: 3.05247 |  0:00:13s\n",
      "epoch 4  | loss: 2.97582 |  0:00:16s\n",
      "epoch 5  | loss: 2.87999 |  0:00:19s\n",
      "epoch 6  | loss: 2.75888 |  0:00:22s\n",
      "epoch 7  | loss: 2.69066 |  0:00:25s\n",
      "epoch 8  | loss: 2.56857 |  0:00:28s\n",
      "epoch 9  | loss: 2.46034 |  0:00:32s\n",
      "epoch 10 | loss: 2.34578 |  0:00:36s\n",
      "epoch 11 | loss: 2.26855 |  0:00:39s\n",
      "epoch 12 | loss: 2.16208 |  0:00:42s\n",
      "epoch 13 | loss: 2.07262 |  0:00:45s\n",
      "epoch 14 | loss: 1.95009 |  0:00:48s\n",
      "epoch 15 | loss: 1.86903 |  0:00:50s\n",
      "epoch 16 | loss: 1.78848 |  0:00:53s\n",
      "epoch 17 | loss: 1.72077 |  0:00:56s\n",
      "epoch 18 | loss: 1.6217  |  0:01:00s\n",
      "epoch 19 | loss: 1.53482 |  0:01:03s\n",
      "epoch 20 | loss: 1.4626  |  0:01:06s\n",
      "epoch 21 | loss: 1.38301 |  0:01:09s\n",
      "epoch 22 | loss: 1.31698 |  0:01:12s\n",
      "epoch 23 | loss: 1.23931 |  0:01:15s\n",
      "epoch 24 | loss: 1.20096 |  0:01:19s\n",
      "epoch 25 | loss: 1.15193 |  0:01:22s\n",
      "epoch 26 | loss: 1.0633  |  0:01:26s\n",
      "epoch 27 | loss: 1.01891 |  0:01:28s\n",
      "epoch 28 | loss: 0.95129 |  0:01:32s\n",
      "epoch 29 | loss: 0.90811 |  0:01:36s\n",
      "epoch 30 | loss: 0.89265 |  0:01:39s\n",
      "epoch 31 | loss: 0.84155 |  0:01:41s\n",
      "epoch 32 | loss: 0.79589 |  0:01:45s\n",
      "epoch 33 | loss: 0.76933 |  0:01:48s\n",
      "epoch 34 | loss: 0.71138 |  0:01:52s\n",
      "epoch 35 | loss: 0.69123 |  0:01:55s\n",
      "epoch 36 | loss: 0.65311 |  0:01:59s\n",
      "epoch 37 | loss: 0.60966 |  0:02:02s\n",
      "epoch 38 | loss: 0.58814 |  0:02:04s\n",
      "epoch 39 | loss: 0.55827 |  0:02:07s\n",
      "epoch 40 | loss: 0.53584 |  0:02:10s\n",
      "epoch 41 | loss: 0.52058 |  0:02:12s\n",
      "epoch 42 | loss: 0.49163 |  0:02:16s\n",
      "epoch 43 | loss: 0.44737 |  0:02:19s\n",
      "epoch 44 | loss: 0.42106 |  0:02:22s\n",
      "epoch 45 | loss: 0.39373 |  0:02:25s\n",
      "epoch 46 | loss: 0.37835 |  0:02:28s\n",
      "epoch 47 | loss: 0.36299 |  0:02:31s\n",
      "epoch 48 | loss: 0.391   |  0:02:34s\n",
      "epoch 49 | loss: 0.3538  |  0:02:37s\n",
      "epoch 50 | loss: 0.33709 |  0:02:40s\n",
      "epoch 51 | loss: 0.36487 |  0:02:43s\n",
      "epoch 52 | loss: 0.32095 |  0:02:46s\n",
      "epoch 53 | loss: 0.34062 |  0:02:49s\n",
      "epoch 54 | loss: 0.31024 |  0:02:52s\n",
      "epoch 55 | loss: 0.28324 |  0:02:54s\n",
      "epoch 56 | loss: 0.29639 |  0:02:56s\n",
      "epoch 57 | loss: 0.28653 |  0:02:58s\n",
      "epoch 58 | loss: 0.28576 |  0:03:02s\n",
      "epoch 59 | loss: 0.3064  |  0:03:06s\n",
      "epoch 60 | loss: 0.2822  |  0:03:08s\n",
      "epoch 61 | loss: 0.27666 |  0:03:11s\n",
      "epoch 62 | loss: 0.25188 |  0:03:14s\n",
      "epoch 63 | loss: 0.26471 |  0:03:17s\n",
      "epoch 64 | loss: 0.25493 |  0:03:19s\n",
      "epoch 65 | loss: 0.25407 |  0:03:21s\n",
      "epoch 66 | loss: 0.23992 |  0:03:24s\n",
      "epoch 67 | loss: 0.24531 |  0:03:27s\n",
      "epoch 68 | loss: 0.23269 |  0:03:30s\n",
      "epoch 69 | loss: 0.2263  |  0:03:33s\n",
      "epoch 70 | loss: 0.22094 |  0:03:36s\n",
      "epoch 71 | loss: 0.22733 |  0:03:38s\n",
      "epoch 72 | loss: 0.23344 |  0:03:41s\n",
      "epoch 73 | loss: 0.23463 |  0:03:44s\n",
      "epoch 74 | loss: 0.21341 |  0:03:46s\n",
      "epoch 75 | loss: 0.21484 |  0:03:49s\n",
      "epoch 76 | loss: 0.21417 |  0:03:52s\n",
      "epoch 77 | loss: 0.19982 |  0:03:54s\n",
      "epoch 78 | loss: 0.19864 |  0:03:57s\n",
      "epoch 79 | loss: 0.19827 |  0:04:00s\n",
      "epoch 80 | loss: 0.20324 |  0:04:04s\n",
      "epoch 81 | loss: 0.19178 |  0:04:08s\n",
      "epoch 82 | loss: 0.18411 |  0:04:11s\n",
      "epoch 83 | loss: 0.1797  |  0:04:15s\n",
      "epoch 84 | loss: 0.18589 |  0:04:19s\n",
      "epoch 85 | loss: 0.21036 |  0:04:23s\n",
      "epoch 86 | loss: 0.18554 |  0:04:26s\n",
      "epoch 87 | loss: 0.20531 |  0:04:28s\n",
      "epoch 88 | loss: 0.17265 |  0:04:31s\n",
      "epoch 89 | loss: 0.17947 |  0:04:34s\n",
      "epoch 90 | loss: 0.16857 |  0:04:38s\n",
      "epoch 91 | loss: 0.18996 |  0:04:41s\n",
      "epoch 92 | loss: 0.17152 |  0:04:44s\n",
      "epoch 93 | loss: 0.17354 |  0:04:46s\n",
      "epoch 94 | loss: 0.15782 |  0:04:47s\n",
      "epoch 95 | loss: 0.16871 |  0:04:50s\n",
      "epoch 96 | loss: 0.18016 |  0:04:52s\n",
      "epoch 97 | loss: 0.16406 |  0:04:55s\n",
      "epoch 98 | loss: 0.19227 |  0:04:59s\n",
      "epoch 99 | loss: 0.17946 |  0:05:02s\n"
=======
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 172, in forward\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 671, in forward\n    x = self.selector(x)\n        ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 109, in forward\n    return sparsemax(input, self.dim)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 52, in forward\n    tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 88, in _threshold_and_support\n    input_srt, _ = torch.sort(input, descending=True, dim=dim)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 278, in fit\n    self.feature_importances_ = self._compute_feature_importances(X_train)\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 759, in _compute_feature_importances\n    M_explain, _ = self.explain(X, normalize=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 356, in explain\n    M_explain, masks = self.network.forward_masks(data)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 620, in forward_masks\n    return self.tabnet.forward_masks(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 505, in forward_masks\n    return self.encoder.forward_masks(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 199, in forward_masks\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 671, in forward\n    x = self.selector(x)\n        ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 109, in forward\n    return sparsemax(input, self.dim)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 52, in forward\n    tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 88, in _threshold_and_support\n    input_srt, _ = torch.sort(input, descending=True, dim=dim)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 737, in forward\n    x = self.shared(x)\n        ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 166, in forward\n    prior = torch.ones((bs, self.attention_dim)).to(x.device)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 738, in forward\n    x = self.specifics(x)\n        ^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 804, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 38, in forward\n    return torch.cat(res, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 172, in forward\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 669, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 36, in forward\n    res = [self.bn(x_) for x_ in chunks]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 36, in <listcomp>\n    res = [self.bn(x_) for x_ in chunks]\n           ^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 175, in forward\n    return F.batch_norm(\n           ^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py\", line 2509, in batch_norm\n    return torch.batch_norm(\n           ^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Xtrain, Ytrain, Xtest, Ytest \u001b[38;5;241m=\u001b[39m split_data(traindata, testdata)\n\u001b[0;32m----> 2\u001b[0m best_tabnet_params \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_tabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Re-initialize TabNet with best params\u001b[39;00m\n\u001b[1;32m      6\u001b[0m final_model \u001b[38;5;241m=\u001b[39m TabNetClassifier(\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m best_tabnet_params\u001b[38;5;241m.\u001b[39mitems()},\n\u001b[1;32m      8\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m      9\u001b[0m     seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mfind_best_tabnet\u001b[0;34m(Xtrain, Ytrain, n_iter)\u001b[0m\n\u001b[1;32m     14\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_d\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m24\u001b[39m],\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_a\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m24\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_params\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m}]\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     23\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     24\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     25\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     32\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1930\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1930\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:945\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    943\u001b[0m     )\n\u001b[0;32m--> 945\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n70 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 172, in forward\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 671, in forward\n    x = self.selector(x)\n        ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 109, in forward\n    return sparsemax(input, self.dim)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 52, in forward\n    tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 88, in _threshold_and_support\n    input_srt, _ = torch.sort(input, descending=True, dim=dim)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n6 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 278, in fit\n    self.feature_importances_ = self._compute_feature_importances(X_train)\n                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 759, in _compute_feature_importances\n    M_explain, _ = self.explain(X, normalize=False)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 356, in explain\n    M_explain, masks = self.network.forward_masks(data)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 620, in forward_masks\n    return self.tabnet.forward_masks(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 505, in forward_masks\n    return self.encoder.forward_masks(x)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 199, in forward_masks\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 671, in forward\n    x = self.selector(x)\n        ^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 109, in forward\n    return sparsemax(input, self.dim)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/function.py\", line 598, in apply\n    return super().apply(*args, **kwargs)  # type: ignore[misc]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 52, in forward\n    tau, supp_size = SparsemaxFunction._threshold_and_support(input, dim=dim)\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/sparsemax.py\", line 88, in _threshold_and_support\n    input_srt, _ = torch.sort(input, descending=True, dim=dim)\n                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 737, in forward\n    x = self.shared(x)\n        ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n20 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 166, in forward\n    prior = torch.ones((bs, self.attention_dim)).to(x.device)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 738, in forward\n    x = self.specifics(x)\n        ^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 804, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 38, in forward\n    return torch.cat(res, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n2 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 172, in forward\n    M = self.att_transformers[step](prior, att)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 669, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 36, in forward\n    res = [self.bn(x_) for x_ in chunks]\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 36, in <listcomp>\n    res = [self.bn(x_) for x_ in chunks]\n           ^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py\", line 175, in forward\n    return F.batch_norm(\n           ^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py\", line 2509, in batch_norm\n    return torch.batch_norm(\n           ^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n"
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "Xtrain, Ytrain, Xtest, Ytest, Ytest_decoded, le = split_data(traindata, testdata)\n",
=======
    "Xtrain, Ytrain, Xtest, Ytest = split_data(traindata, testdata)\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "best_tabnet_params = find_best_tabnet(Xtrain, Ytrain)\n",
    "\n",
    "\n",
    "# Re-initialize TabNet with best params\n",
    "final_model = TabNetClassifier(\n",
    "    **{k: v for k, v in best_tabnet_params.items()},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
<<<<<<< HEAD
    "fit_params = {\n",
    "    'max_epochs': 100,        # adjust as needed\n",
    "    'batch_size': 64,        # lower if you get CUDA OOM\n",
    "    'virtual_batch_size': 16, # smaller \"sub-batches\" to reduce memory usage\n",
    "    'patience': 10,\n",
    "    'drop_last': False\n",
    "}\n",
    "\n",
    "# Retrain on full training data\n",
    "final_model.fit(\n",
    "    Xtrain, Ytrain, **fit_params\n",
=======
    "# Retrain on full training data\n",
    "final_model.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": null,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Predict class indices for test set\n",
    "y_pred = final_model.predict(Xtest)\n",
<<<<<<< HEAD
    "y_pred_decoded = le.inverse_transform(y_pred)\n",
=======
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "\n",
    "# Compute and print accuracy\n",
    "acc = accuracy_score(Ytest, y_pred)\n",
    "file_path = os.path.join(\"results\", f\"gtd{partition}.txt\")\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Write a string to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(str(acc))"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "\n",
    "with open(f'Results/tabnet_{partition}', \"w\") as f:\n",
    "    f.write(f\"Accuracy: {acc*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       1.00      0.45      0.62        60\n",
      "        African National Congress (South Africa)       0.66      0.77      0.71        60\n",
      "                                Al-Qaida in Iraq       0.60      0.70      0.65        60\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.88      0.35      0.50        60\n",
      "                                      Al-Shabaab       0.09      0.83      0.17        60\n",
      "             Basque Fatherland and Freedom (ETA)       0.44      0.57      0.49        60\n",
      "                                      Boko Haram       0.61      0.33      0.43        60\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.27      0.10      0.15        60\n",
      "       Corsican National Liberation Front (FLNC)       0.57      0.95      0.71        60\n",
      "                       Donetsk People's Republic       0.77      0.67      0.71        60\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.73      0.60      0.66        60\n",
      "                               Fulani extremists       0.88      0.12      0.21        60\n",
      "                 Houthi extremists (Ansar Allah)       0.45      0.45      0.45        60\n",
      "                     Irish Republican Army (IRA)       0.54      0.80      0.64        60\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.27      0.17      0.21        60\n",
      "                  Kurdistan Workers' Party (PKK)       0.57      0.20      0.30        60\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.52      0.53      0.53        60\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       0.76      0.90      0.82        60\n",
      "                                         Maoists       0.18      0.07      0.10        60\n",
      "                               Muslim extremists       0.31      0.25      0.28        60\n",
      "      National Liberation Army of Colombia (ELN)       0.50      0.08      0.14        60\n",
      "                         New People's Army (NPA)       0.29      0.03      0.06        60\n",
      "               Nicaraguan Democratic Force (FDN)       0.93      0.22      0.35        60\n",
      "                                    Palestinians       1.00      0.65      0.79        60\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.39      0.18      0.25        60\n",
      "                               Shining Path (SL)       0.46      0.18      0.26        60\n",
      "                                 Sikh Extremists       0.55      0.52      0.53        60\n",
      "                                         Taliban       0.46      0.20      0.28        60\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.62      0.42      0.50        60\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.64      0.75      0.69        60\n",
      "\n",
      "                                        accuracy                           0.43      1800\n",
      "                                       macro avg       0.56      0.43      0.44      1800\n",
      "                                    weighted avg       0.56      0.43      0.44      1800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = f\"Results/confusion_matrix_partition_{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition {partition} to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition 200 to Results/confusion_matrix_partition_200.png\n"
     ]
    }
   ],
   "source": [
    "# Get all unique class labels from the truths\n",
    "class_labels = np.unique(Ytest_decoded)\n",
    "\n",
    "plot_confusion_matrix(Ytest_decoded, y_pred_decoded, labels=class_labels)\n",
    "\n"
   ]
=======
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TabNet)",
   "language": "python",
   "name": "tabnet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
