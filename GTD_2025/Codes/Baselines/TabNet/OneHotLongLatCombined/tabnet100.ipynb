{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in /opt/conda/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.5.0)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (4.66.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pytorch-tabnet --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../../data/top30groups/OneHotLongLatCombined/train1/train{partition}.csv'\n",
    "testpath = f'../../../../data/top30groups/OneHotLongLatCombined/test1/test{partition}.csv'\n",
    "\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def split_data(dftrain, dftest):\n",
    "    Xtrain = dftrain.drop(columns=['gname']).values.astype(float)\n",
    "    Ytrain = dftrain['gname'].values\n",
    "    Xtest = dftest.drop(columns=['gname']).values.astype(float)\n",
    "    Ytest = dftest['gname'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    Ytrain = le.fit_transform(Ytrain)\n",
    "    Ytest = le.transform(Ytest)\n",
    "\n",
    "    #y_pred_decoded = model.label_encoder.inverse_transform(y_pred)\n",
    "    y_true_decoded = le.inverse_transform(Ytest)\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, y_true_decoded, le\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import numpy as np\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "class TabNetClassifierWrapper(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_d=8, n_a=8, n_steps=3, gamma=1.3, lambda_sparse=1e-3, optimizer_params=None):\n",
    "        self.n_d = n_d\n",
    "        self.n_a = n_a\n",
    "        self.n_steps = n_steps\n",
    "        self.gamma = gamma\n",
    "        self.lambda_sparse = lambda_sparse\n",
    "        self.optimizer_params = optimizer_params or {'lr': 0.01}\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.model = TabNetClassifier(\n",
    "            n_d=self.n_d,\n",
    "            n_a=self.n_a,\n",
    "            n_steps=self.n_steps,\n",
    "            gamma=self.gamma,\n",
    "            lambda_sparse=self.lambda_sparse,\n",
    "            optimizer_params=self.optimizer_params,\n",
    "            seed=42,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        self.model.fit(\n",
    "            X, y,\n",
    "            eval_set=[(X, y)],\n",
    "            max_epochs=200,\n",
    "            patience=20,\n",
    "            batch_size=1024,\n",
    "            virtual_batch_size=128,\n",
    "            eval_metric=['accuracy']\n",
    "        )\n",
    "\n",
    "        self.classes_ = np.unique(y)  \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        preds = self.predict(X)\n",
    "        return (preds == y).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch_tabnet.sklearn import TabNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "def find_best_tabnet(Xtrain, Ytrain, n_iter=20):\n",
    "    print(\"Starting TabNet grid search\")\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "    param_dist = {\n",
    "        'n_d': [8, 16, 24],\n",
    "        'n_a': [8, 16, 24],\n",
    "        'n_steps': [3, 4, 5],\n",
    "        'gamma': [1.0, 1.3, 1.5],\n",
    "        'lambda_sparse': [1e-4, 1e-3, 1e-2],\n",
    "        'optimizer_params': [{'lr': 0.01}]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=TabNetClassifierWrapper(),\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(Xtrain, Ytrain)\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best accuracy:\", random_search.best_score_)\n",
    "\n",
    "    return random_search.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.callbacks import Callback\n",
    "import time\n",
    "\n",
    "class EpochTimer(Callback):\n",
    "    def __init__(self):\n",
    "        self.epoch_times = []\n",
    "\n",
    "    def on_epoch_begin(self, epoch_idx, logs=None):\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch_idx, logs=None):\n",
    "        duration = time.time() - self.start_time\n",
    "        self.epoch_times.append(duration)\n",
    "        print(f\"⏱️ Epoch {epoch_idx + 1} took {duration:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TabNet grid search\n",
      "CUDA available: True\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n17 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 519, in _train_batch\n    y = y.to(self.device).float()\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 534, in _train_batch\n    loss.backward()\n  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n    torch.autograd.backward(\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n    _engine_run_backward(\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n16 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 174, in forward\n    torch.sum(torch.mul(M, torch.log(M + self.epsilon)), dim=1)\nRuntimeError: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 737, in forward\n    x = self.shared(x)\n        ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 804, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 38, in forward\n    return torch.cat(res, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n63 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 240, in fit\n    self._set_network()\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 621, in _set_network\n    group_attention_matrix=self.group_matrix.to(self.device),\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Xtrain, Ytrain, Xtest, Ytest, Ytest_decoded, le \u001b[38;5;241m=\u001b[39m split_data(traindata, testdata)\n\u001b[0;32m----> 2\u001b[0m best_tabnet_params \u001b[38;5;241m=\u001b[39m \u001b[43mfind_best_tabnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Split 80% train, 20% validation\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 32\u001b[0m, in \u001b[0;36mfind_best_tabnet\u001b[0;34m(Xtrain, Ytrain, n_iter)\u001b[0m\n\u001b[1;32m     12\u001b[0m param_dist \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_d\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m24\u001b[39m],\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_a\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m24\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_params\u001b[39m\u001b[38;5;124m'\u001b[39m: [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.01\u001b[39m}]\n\u001b[1;32m     19\u001b[0m }\n\u001b[1;32m     21\u001b[0m random_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[1;32m     22\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mTabNetClassifierWrapper(),\n\u001b[1;32m     23\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m \u001b[43mrandom_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, random_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:968\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    962\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    963\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    964\u001b[0m     )\n\u001b[1;32m    966\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 968\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    972\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1930\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1929\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1930\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1932\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_search.py:945\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    943\u001b[0m     )\n\u001b[0;32m--> 945\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    528\u001b[0m     )\n\u001b[0;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    539\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 100 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n17 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 519, in _train_batch\n    y = y.to(self.device).float()\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\n--------------------------------------------------------------------------------\n3 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 534, in _train_batch\n    loss.backward()\n  File \"/opt/conda/lib/python3.11/site-packages/torch/_tensor.py\", line 525, in backward\n    torch.autograd.backward(\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py\", line 267, in backward\n    _engine_run_backward(\n  File \"/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py\", line 744, in _engine_run_backward\n    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n16 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 174, in forward\n    torch.sum(torch.mul(M, torch.log(M + self.epsilon)), dim=1)\nRuntimeError: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n\n--------------------------------------------------------------------------------\n1 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 258, in fit\n    self._train_epoch(train_dataloader)\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 489, in _train_epoch\n    batch_logs = self._train_batch(X, y)\n                 ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 527, in _train_batch\n    output, M_loss = self.network(X)\n                     ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 616, in forward\n    return self.tabnet(x)\n           ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 492, in forward\n    steps_output, M_loss = self.encoder(x)\n                           ^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 181, in forward\n    out = self.feat_transformers[step](masked_x)\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 737, in forward\n    x = self.shared(x)\n        ^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 780, in forward\n    x = torch.add(x, self.glu_layers[glu_id](x))\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 804, in forward\n    x = self.bn(x)\n        ^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1532, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1541, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/tab_network.py\", line 38, in forward\n    return torch.cat(res, dim=0)\n           ^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: NVML_SUCCESS == r INTERNAL ASSERT FAILED at \"../c10/cuda/CUDACachingAllocator.cpp\":844, please report a bug to PyTorch. \n\n--------------------------------------------------------------------------------\n63 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/tmp/ipykernel_23500/1674612731.py\", line 27, in fit\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 240, in fit\n    self._set_network()\n  File \"/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py\", line 621, in _set_network\n    group_attention_matrix=self.group_matrix.to(self.device),\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, Xtest, Ytest, Ytest_decoded, le = split_data(traindata, testdata)\n",
    "best_tabnet_params = find_best_tabnet(Xtrain, Ytrain)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split 80% train, 20% validation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    Xtrain, Ytrain,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=Ytrain\n",
    ")\n",
    "\n",
    "# Re-initialize TabNet with best params\n",
    "final_model = TabNetClassifier(\n",
    "    **{k: v for k, v in best_tabnet_params.items()},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "epoch_timer = EpochTimer()\n",
    "\n",
    "# Retrain on full training data\n",
    "final_model.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    max_epochs=1000,\n",
    "    patience=50,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    callbacks=[epoch_timer]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "file_path = os.path.join(\"results\", f\"gtd{partition}.txt\")\n",
    "\n",
    "# Predict class indices for test set\n",
    "y_pred = final_model.predict(Xtest)\n",
    "y_proba = final_model.predict_proba(Xtest)\n",
    "y_pred_decoded = le.inverse_transform(y_pred)\n",
    "y_true_decoded = le.inverse_transform(Ytest)\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Compute accuracy from decoded labels\n",
    "acc = accuracy_score(y_true_decoded, y_pred_decoded)\n",
    "\n",
    "# Write metrics to file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(f\"Accuracy: {acc:.4f}\\n\")\n",
    "    file.write(f\"Precision weighted: {precision_score(y_true_decoded, y_pred_decoded, average='weighted'):.4f}\\n\")\n",
    "    file.write(f\"Recall weighted: {recall_score(y_true_decoded, y_pred_decoded, average='weighted'):.4f}\\n\")\n",
    "    file.write(f\"F1 Score weighted: {f1_score(y_true_decoded, y_pred_decoded, average='weighted'):.4f}\\n\")\n",
    "    file.write(f\"Precision micro: {precision_score(y_true_decoded, y_pred_decoded, average='micro'):.4f}\\n\")\n",
    "    file.write(f\"Recall micro: {recall_score(y_true_decoded, y_pred_decoded, average='micro'):.4f}\\n\")\n",
    "    file.write(f\"F1 Score micro: {f1_score(y_true_decoded, y_pred_decoded, average='micro'):.4f}\\n\")\n",
    "    file.write(f\"Precision macro: {precision_score(y_true_decoded, y_pred_decoded, average='macro'):.4f}\\n\")\n",
    "    file.write(f\"Recall macro: {recall_score(y_true_decoded, y_pred_decoded, average='macro'):.4f}\\n\")\n",
    "    file.write(f\"F1 Score macro: {f1_score(y_true_decoded, y_pred_decoded, average='macro'):.4f}\\n\")\n",
    "    file.write(f\"roc auc weighted: {roc_auc_score(y_true_decoded, y_proba, multi_class='ovr', average='weighted'):.4f}\\n\")\n",
    "    file.write(f\"roc auc macro: {roc_auc_score(y_true_decoded, y_proba, multi_class='ovr', average='macro'):.4f}\\n\")\n",
    "    file.write(f\"roc auc micro: {roc_auc_score(y_true_decoded, y_proba, multi_class='ovr', average='micro'):.4f}\\n\")\n",
    "\n",
    "with open(f\"results/epoch_time_gtd{partition}.txt\", \"w\") as f:\n",
    "    f.write('\\n'.join(str(x) for x in epoch_timer.epoch_times))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       0.89      0.57      0.69        30\n",
      "        African National Congress (South Africa)       1.00      1.00      1.00        30\n",
      "                                Al-Qaida in Iraq       0.57      0.53      0.55        30\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.83      0.63      0.72        30\n",
      "                                      Al-Shabaab       1.00      0.90      0.95        30\n",
      "             Basque Fatherland and Freedom (ETA)       0.75      0.20      0.32        30\n",
      "                                      Boko Haram       0.58      0.93      0.72        30\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.72      0.97      0.83        30\n",
      "       Corsican National Liberation Front (FLNC)       0.51      0.87      0.64        30\n",
      "                       Donetsk People's Republic       0.91      1.00      0.95        30\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.70      1.00      0.82        30\n",
      "                               Fulani extremists       1.00      0.33      0.50        30\n",
      "                 Houthi extremists (Ansar Allah)       0.67      0.93      0.78        30\n",
      "                     Irish Republican Army (IRA)       0.69      0.37      0.48        30\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.42      0.43      0.43        30\n",
      "                  Kurdistan Workers' Party (PKK)       0.57      0.77      0.66        30\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.96      0.83      0.89        30\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       1.00      0.93      0.97        30\n",
      "                                         Maoists       0.86      0.63      0.73        30\n",
      "                               Muslim extremists       0.29      0.30      0.30        30\n",
      "      National Liberation Army of Colombia (ELN)       0.25      0.07      0.11        30\n",
      "                         New People's Army (NPA)       0.65      0.93      0.77        30\n",
      "               Nicaraguan Democratic Force (FDN)       0.82      0.47      0.60        30\n",
      "                                    Palestinians       0.85      0.77      0.81        30\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.43      0.80      0.56        30\n",
      "                               Shining Path (SL)       0.73      0.37      0.49        30\n",
      "                                 Sikh Extremists       0.67      0.20      0.31        30\n",
      "                                         Taliban       0.81      0.43      0.57        30\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.42      0.93      0.58        30\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.59      0.90      0.71        30\n",
      "\n",
      "                                        accuracy                           0.67       900\n",
      "                                       macro avg       0.71      0.67      0.65       900\n",
      "                                    weighted avg       0.71      0.67      0.65       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = f\"results/confusion_matrix_partition_{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition {partition} to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition 100 to results/confusion_matrix_partition_100.png\n"
     ]
    }
   ],
   "source": [
    "# Get all unique class labels from the truths\n",
    "class_labels = np.unique(Ytest_decoded)\n",
    "\n",
    "plot_confusion_matrix(Ytest_decoded, y_pred_decoded, labels=class_labels)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TabNet)",
   "language": "python",
   "name": "tabnet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
