{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 9,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 10,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 100"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 11,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-tabnet in /opt/conda/lib/python3.11/site-packages (4.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.26.4)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.5.0)\n",
      "Requirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (1.14.0)\n",
      "Requirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.11/site-packages (from pytorch-tabnet) (4.66.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.11/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (1.12.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.1 in /opt/conda/lib/python3.11/site-packages (from torch>=1.3->pytorch-tabnet) (2.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.3->pytorch-tabnet) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!{sys.executable} -m pip install pytorch-tabnet --upgrade"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 12,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../../data/top30groups/DNDF_OneHotLongLatCombined/train/train{partition}.csv'\n",
    "testpath = f'../../../../data/top30groups/DNDF_OneHotLongLatCombined/test/test{partition}.csv'\n",
    "\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 13,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
=======
   "execution_count": 14,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 15,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def split_data(dftrain, dftest):\n",
    "    Xtrain = dftrain.drop(columns=['gname']).values.astype(float)\n",
    "    Ytrain = dftrain['gname'].values\n",
    "    Xtest = dftest.drop(columns=['gname']).values.astype(float)\n",
    "    Ytest = dftest['gname'].values\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    Ytrain = le.fit_transform(Ytrain)\n",
    "    Ytest = le.transform(Ytest)\n",
    "\n",
<<<<<<< HEAD
    "    #y_pred_decoded = model.label_encoder.inverse_transform(y_pred)\n",
    "    y_true_decoded = le.inverse_transform(Ytest)\n",
    "\n",
    "    return Xtrain, Ytrain, Xtest, Ytest, y_true_decoded, le\n",
=======
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 16,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pytorch_tabnet.sklearn import TabNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier, TabNetRegressor\n",
    "\n",
    "\n",
    "def find_best_tabnet(Xtrain, Ytrain, n_iter=20):\n",
    "    print(\"Starting TabNet grid search\")\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    model = TabNetClassifier(verbose=0, seed=42)\n",
    "\n",
    "    param_dist = {\n",
    "        'n_d': [8, 16, 24],\n",
    "        'n_a': [8, 16, 24],\n",
    "        'n_steps': [3, 4, 5],\n",
    "        'gamma': [1.0, 1.3, 1.5],\n",
    "        'lambda_sparse': [1e-4, 1e-3, 1e-2],\n",
    "        'optimizer_params': [{'lr': 0.01}]\n",
    "    }\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42),\n",
    "        scoring='accuracy',\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    random_search.fit(Xtrain, Ytrain)\n",
    "    print(\"Best parameters:\", random_search.best_params_)\n",
    "    print(\"Best accuracy:\", random_search.best_score_)\n",
    "\n",
    "    return random_search.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 17,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TabNet grid search\n",
      "CUDA available: True\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n",
      "/opt/conda/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:687: UserWarning: No early stopping will be performed, last training weights will be used.\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'optimizer_params': {'lr': 0.01}, 'n_steps': 3, 'n_d': 24, 'n_a': 8, 'lambda_sparse': 0.0001, 'gamma': 1.0}\n",
      "Best accuracy: 0.06761904761904762\n",
      "epoch 0  | loss: 4.09536 |  0:00:00s\n",
      "epoch 1  | loss: 3.9809  |  0:00:00s\n",
      "epoch 2  | loss: 3.9652  |  0:00:00s\n",
<<<<<<< HEAD
      "epoch 3  | loss: 3.87684 |  0:00:01s\n",
      "epoch 4  | loss: 3.9295  |  0:00:01s\n",
      "epoch 5  | loss: 3.82458 |  0:00:01s\n",
      "epoch 6  | loss: 3.79256 |  0:00:01s\n",
      "epoch 7  | loss: 3.73725 |  0:00:02s\n",
      "epoch 8  | loss: 3.71467 |  0:00:02s\n",
      "epoch 9  | loss: 3.64762 |  0:00:02s\n",
      "epoch 10 | loss: 3.62551 |  0:00:02s\n",
      "epoch 11 | loss: 3.647   |  0:00:03s\n",
      "epoch 12 | loss: 3.6114  |  0:00:03s\n",
      "epoch 13 | loss: 3.59176 |  0:00:03s\n",
      "epoch 14 | loss: 3.54309 |  0:00:03s\n",
      "epoch 15 | loss: 3.5436  |  0:00:03s\n",
      "epoch 16 | loss: 3.53471 |  0:00:04s\n",
=======
      "epoch 3  | loss: 3.87684 |  0:00:00s\n",
      "epoch 4  | loss: 3.9295  |  0:00:01s\n",
      "epoch 5  | loss: 3.82458 |  0:00:01s\n",
      "epoch 6  | loss: 3.79256 |  0:00:01s\n",
      "epoch 7  | loss: 3.73725 |  0:00:01s\n",
      "epoch 8  | loss: 3.71467 |  0:00:02s\n",
      "epoch 9  | loss: 3.64762 |  0:00:02s\n",
      "epoch 10 | loss: 3.62551 |  0:00:02s\n",
      "epoch 11 | loss: 3.647   |  0:00:02s\n",
      "epoch 12 | loss: 3.6114  |  0:00:02s\n",
      "epoch 13 | loss: 3.59176 |  0:00:03s\n",
      "epoch 14 | loss: 3.54309 |  0:00:03s\n",
      "epoch 15 | loss: 3.5436  |  0:00:03s\n",
      "epoch 16 | loss: 3.53471 |  0:00:03s\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
      "epoch 17 | loss: 3.50222 |  0:00:04s\n",
      "epoch 18 | loss: 3.48978 |  0:00:04s\n",
      "epoch 19 | loss: 3.4841  |  0:00:04s\n",
      "epoch 20 | loss: 3.43411 |  0:00:05s\n",
      "epoch 21 | loss: 3.45436 |  0:00:05s\n",
      "epoch 22 | loss: 3.42789 |  0:00:05s\n",
      "epoch 23 | loss: 3.46091 |  0:00:05s\n",
<<<<<<< HEAD
      "epoch 24 | loss: 3.45321 |  0:00:05s\n",
      "epoch 25 | loss: 3.42858 |  0:00:06s\n",
      "epoch 26 | loss: 3.42324 |  0:00:06s\n",
      "epoch 27 | loss: 3.41844 |  0:00:06s\n",
      "epoch 28 | loss: 3.3856  |  0:00:06s\n",
      "epoch 29 | loss: 3.3665  |  0:00:07s\n",
      "epoch 30 | loss: 3.37549 |  0:00:07s\n",
      "epoch 31 | loss: 3.34399 |  0:00:07s\n",
      "epoch 32 | loss: 3.34229 |  0:00:08s\n",
      "epoch 33 | loss: 3.34004 |  0:00:08s\n",
      "epoch 34 | loss: 3.34466 |  0:00:08s\n",
      "epoch 35 | loss: 3.35551 |  0:00:08s\n",
      "epoch 36 | loss: 3.36272 |  0:00:09s\n",
      "epoch 37 | loss: 3.3345  |  0:00:09s\n",
      "epoch 38 | loss: 3.32711 |  0:00:09s\n",
      "epoch 39 | loss: 3.29679 |  0:00:09s\n",
      "epoch 40 | loss: 3.26662 |  0:00:09s\n",
      "epoch 41 | loss: 3.23528 |  0:00:10s\n",
      "epoch 42 | loss: 3.20264 |  0:00:10s\n",
      "epoch 43 | loss: 3.21595 |  0:00:10s\n",
      "epoch 44 | loss: 3.18861 |  0:00:10s\n",
      "epoch 45 | loss: 3.16008 |  0:00:11s\n",
      "epoch 46 | loss: 3.16278 |  0:00:11s\n",
      "epoch 47 | loss: 3.10491 |  0:00:11s\n",
      "epoch 48 | loss: 3.07882 |  0:00:11s\n",
      "epoch 49 | loss: 3.06442 |  0:00:12s\n",
      "epoch 50 | loss: 2.99498 |  0:00:12s\n",
      "epoch 51 | loss: 2.94567 |  0:00:12s\n",
      "epoch 52 | loss: 2.89968 |  0:00:13s\n",
      "epoch 53 | loss: 2.83985 |  0:00:13s\n",
      "epoch 54 | loss: 2.79431 |  0:00:13s\n",
      "epoch 55 | loss: 2.7928  |  0:00:14s\n",
      "epoch 56 | loss: 2.6871  |  0:00:14s\n",
      "epoch 57 | loss: 2.62062 |  0:00:14s\n",
      "epoch 58 | loss: 2.57384 |  0:00:14s\n",
      "epoch 59 | loss: 2.50347 |  0:00:15s\n",
      "epoch 60 | loss: 2.46355 |  0:00:15s\n",
      "epoch 61 | loss: 2.39867 |  0:00:15s\n",
      "epoch 62 | loss: 2.31622 |  0:00:16s\n",
      "epoch 63 | loss: 2.25986 |  0:00:16s\n",
      "epoch 64 | loss: 2.17416 |  0:00:16s\n",
      "epoch 65 | loss: 2.13112 |  0:00:16s\n",
      "epoch 66 | loss: 2.04395 |  0:00:17s\n",
      "epoch 67 | loss: 1.96982 |  0:00:17s\n",
      "epoch 68 | loss: 1.91453 |  0:00:17s\n",
      "epoch 69 | loss: 1.8602  |  0:00:17s\n",
      "epoch 70 | loss: 1.79646 |  0:00:18s\n",
      "epoch 71 | loss: 1.74061 |  0:00:18s\n",
      "epoch 72 | loss: 1.64837 |  0:00:18s\n",
      "epoch 73 | loss: 1.60165 |  0:00:18s\n",
      "epoch 74 | loss: 1.55953 |  0:00:19s\n",
      "epoch 75 | loss: 1.50486 |  0:00:19s\n",
      "epoch 76 | loss: 1.44999 |  0:00:19s\n",
      "epoch 77 | loss: 1.33374 |  0:00:19s\n",
      "epoch 78 | loss: 1.32526 |  0:00:19s\n",
      "epoch 79 | loss: 1.28057 |  0:00:20s\n",
      "epoch 80 | loss: 1.24857 |  0:00:20s\n",
      "epoch 81 | loss: 1.18258 |  0:00:20s\n",
      "epoch 82 | loss: 1.11713 |  0:00:20s\n",
      "epoch 83 | loss: 1.07712 |  0:00:21s\n",
      "epoch 84 | loss: 1.04931 |  0:00:21s\n",
      "epoch 85 | loss: 0.98505 |  0:00:21s\n",
      "epoch 86 | loss: 1.0162  |  0:00:22s\n",
      "epoch 87 | loss: 0.94962 |  0:00:22s\n",
      "epoch 88 | loss: 0.90249 |  0:00:22s\n",
      "epoch 89 | loss: 0.89559 |  0:00:23s\n",
      "epoch 90 | loss: 0.85526 |  0:00:23s\n",
      "epoch 91 | loss: 0.80403 |  0:00:23s\n",
      "epoch 92 | loss: 0.77503 |  0:00:23s\n",
      "epoch 93 | loss: 0.78246 |  0:00:23s\n",
      "epoch 94 | loss: 0.76795 |  0:00:24s\n",
      "epoch 95 | loss: 0.69879 |  0:00:24s\n",
      "epoch 96 | loss: 0.69737 |  0:00:24s\n",
      "epoch 97 | loss: 0.65896 |  0:00:24s\n",
      "epoch 98 | loss: 0.62483 |  0:00:25s\n",
      "epoch 99 | loss: 0.61175 |  0:00:25s\n"
=======
      "epoch 24 | loss: 3.45321 |  0:00:06s\n",
      "epoch 25 | loss: 3.42858 |  0:00:06s\n",
      "epoch 26 | loss: 3.42324 |  0:00:07s\n",
      "epoch 27 | loss: 3.41844 |  0:00:07s\n",
      "epoch 28 | loss: 3.3856  |  0:00:07s\n",
      "epoch 29 | loss: 3.3665  |  0:00:08s\n",
      "epoch 30 | loss: 3.37549 |  0:00:08s\n",
      "epoch 31 | loss: 3.34399 |  0:00:08s\n",
      "epoch 32 | loss: 3.34229 |  0:00:09s\n",
      "epoch 33 | loss: 3.34004 |  0:00:09s\n",
      "epoch 34 | loss: 3.34466 |  0:00:10s\n",
      "epoch 35 | loss: 3.35551 |  0:00:10s\n",
      "epoch 36 | loss: 3.36272 |  0:00:10s\n",
      "epoch 37 | loss: 3.3345  |  0:00:10s\n",
      "epoch 38 | loss: 3.32711 |  0:00:11s\n",
      "epoch 39 | loss: 3.29679 |  0:00:11s\n",
      "epoch 40 | loss: 3.26662 |  0:00:11s\n",
      "epoch 41 | loss: 3.23528 |  0:00:11s\n",
      "epoch 42 | loss: 3.20264 |  0:00:12s\n",
      "epoch 43 | loss: 3.21595 |  0:00:12s\n",
      "epoch 44 | loss: 3.18861 |  0:00:12s\n",
      "epoch 45 | loss: 3.16008 |  0:00:12s\n",
      "epoch 46 | loss: 3.16278 |  0:00:13s\n",
      "epoch 47 | loss: 3.10491 |  0:00:13s\n",
      "epoch 48 | loss: 3.07882 |  0:00:13s\n",
      "epoch 49 | loss: 3.06442 |  0:00:13s\n",
      "epoch 50 | loss: 2.99498 |  0:00:14s\n",
      "epoch 51 | loss: 2.94567 |  0:00:14s\n",
      "epoch 52 | loss: 2.89968 |  0:00:14s\n",
      "epoch 53 | loss: 2.83985 |  0:00:14s\n",
      "epoch 54 | loss: 2.79431 |  0:00:14s\n",
      "epoch 55 | loss: 2.7928  |  0:00:15s\n",
      "epoch 56 | loss: 2.6871  |  0:00:15s\n",
      "epoch 57 | loss: 2.62062 |  0:00:15s\n",
      "epoch 58 | loss: 2.57384 |  0:00:16s\n",
      "epoch 59 | loss: 2.50347 |  0:00:16s\n",
      "epoch 60 | loss: 2.46355 |  0:00:16s\n",
      "epoch 61 | loss: 2.39867 |  0:00:16s\n",
      "epoch 62 | loss: 2.31622 |  0:00:16s\n",
      "epoch 63 | loss: 2.25986 |  0:00:17s\n",
      "epoch 64 | loss: 2.17416 |  0:00:17s\n",
      "epoch 65 | loss: 2.13112 |  0:00:17s\n",
      "epoch 66 | loss: 2.04395 |  0:00:18s\n",
      "epoch 67 | loss: 1.96982 |  0:00:18s\n",
      "epoch 68 | loss: 1.91453 |  0:00:18s\n",
      "epoch 69 | loss: 1.8602  |  0:00:18s\n",
      "epoch 70 | loss: 1.79646 |  0:00:19s\n",
      "epoch 71 | loss: 1.74061 |  0:00:19s\n",
      "epoch 72 | loss: 1.64837 |  0:00:20s\n",
      "epoch 73 | loss: 1.60165 |  0:00:20s\n",
      "epoch 74 | loss: 1.55953 |  0:00:21s\n",
      "epoch 75 | loss: 1.50486 |  0:00:21s\n",
      "epoch 76 | loss: 1.44999 |  0:00:21s\n",
      "epoch 77 | loss: 1.33374 |  0:00:21s\n",
      "epoch 78 | loss: 1.32526 |  0:00:22s\n",
      "epoch 79 | loss: 1.28057 |  0:00:22s\n",
      "epoch 80 | loss: 1.24857 |  0:00:22s\n",
      "epoch 81 | loss: 1.18258 |  0:00:23s\n",
      "epoch 82 | loss: 1.11713 |  0:00:23s\n",
      "epoch 83 | loss: 1.07712 |  0:00:23s\n",
      "epoch 84 | loss: 1.04931 |  0:00:23s\n",
      "epoch 85 | loss: 0.98505 |  0:00:23s\n",
      "epoch 86 | loss: 1.0162  |  0:00:24s\n",
      "epoch 87 | loss: 0.94962 |  0:00:24s\n",
      "epoch 88 | loss: 0.90249 |  0:00:24s\n",
      "epoch 89 | loss: 0.89559 |  0:00:24s\n",
      "epoch 90 | loss: 0.85526 |  0:00:25s\n",
      "epoch 91 | loss: 0.80403 |  0:00:25s\n",
      "epoch 92 | loss: 0.77503 |  0:00:25s\n",
      "epoch 93 | loss: 0.78246 |  0:00:25s\n",
      "epoch 94 | loss: 0.76795 |  0:00:26s\n",
      "epoch 95 | loss: 0.69879 |  0:00:26s\n",
      "epoch 96 | loss: 0.69737 |  0:00:26s\n",
      "epoch 97 | loss: 0.65896 |  0:00:26s\n",
      "epoch 98 | loss: 0.62483 |  0:00:27s\n",
      "epoch 99 | loss: 0.61175 |  0:00:27s\n"
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "Xtrain, Ytrain, Xtest, Ytest, Ytest_decoded, le = split_data(traindata, testdata)\n",
=======
    "Xtrain, Ytrain, Xtest, Ytest = split_data(traindata, testdata)\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "best_tabnet_params = find_best_tabnet(Xtrain, Ytrain)\n",
    "\n",
    "\n",
    "# Re-initialize TabNet with best params\n",
    "final_model = TabNetClassifier(\n",
    "    **{k: v for k, v in best_tabnet_params.items()},\n",
    "    verbose=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Retrain on full training data\n",
    "final_model.fit(\n",
    "    Xtrain, Ytrain,\n",
    "    max_epochs=100,\n",
    "    patience=20,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, _, _, _, le = split_data(traindata, testdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
=======
   "execution_count": 18,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Predict class indices for test set\n",
    "y_pred = final_model.predict(Xtest)\n",
<<<<<<< HEAD
    "y_pred_decoded = le.inverse_transform(y_pred)\n",
=======
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "\n",
    "# Compute and print accuracy\n",
    "acc = accuracy_score(Ytest, y_pred)\n",
    "file_path = os.path.join(\"results\", f\"gtd{partition}.txt\")\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Write a string to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(str(acc))"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "\n",
    "with open(f'Results/tabnet_{partition}', \"w\") as f:\n",
    "    f.write(f\"Accuracy: {acc*100:.2f}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       0.00      0.00      0.00        30\n",
      "        African National Congress (South Africa)       0.04      0.20      0.06        30\n",
      "                                Al-Qaida in Iraq       1.00      0.07      0.12        30\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.20      0.13      0.16        30\n",
      "                                      Al-Shabaab       0.00      0.00      0.00        30\n",
      "             Basque Fatherland and Freedom (ETA)       0.00      0.00      0.00        30\n",
      "                                      Boko Haram       0.00      0.00      0.00        30\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.01      0.03      0.01        30\n",
      "       Corsican National Liberation Front (FLNC)       0.20      0.10      0.13        30\n",
      "                       Donetsk People's Republic       0.86      0.20      0.32        30\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.00      0.00      0.00        30\n",
      "                               Fulani extremists       0.00      0.00      0.00        30\n",
      "                 Houthi extremists (Ansar Allah)       1.00      0.27      0.42        30\n",
      "                     Irish Republican Army (IRA)       0.43      0.40      0.41        30\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.38      0.17      0.23        30\n",
      "                  Kurdistan Workers' Party (PKK)       0.05      0.27      0.08        30\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.00      0.00      0.00        30\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       1.00      0.47      0.64        30\n",
      "                                         Maoists       0.00      0.00      0.00        30\n",
      "                               Muslim extremists       0.00      0.00      0.00        30\n",
      "      National Liberation Army of Colombia (ELN)       0.00      0.00      0.00        30\n",
      "                         New People's Army (NPA)       0.00      0.00      0.00        30\n",
      "               Nicaraguan Democratic Force (FDN)       0.00      0.00      0.00        30\n",
      "                                    Palestinians       0.00      0.00      0.00        30\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.03      0.03      0.03        30\n",
      "                               Shining Path (SL)       0.09      0.07      0.08        30\n",
      "                                 Sikh Extremists       0.00      0.00      0.00        30\n",
      "                                         Taliban       0.00      0.00      0.00        30\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.20      0.03      0.06        30\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.12      0.80      0.21        30\n",
      "\n",
      "                                        accuracy                           0.11       900\n",
      "                                       macro avg       0.19      0.11      0.10       900\n",
      "                                    weighted avg       0.19      0.11      0.10       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = f\"Results/confusion_matrix_partition_{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition {partition} to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition 100 to Results/confusion_matrix_partition_100.png\n"
     ]
    }
   ],
   "source": [
    "# Get all unique class labels from the truths\n",
    "class_labels = np.unique(Ytest_decoded)\n",
    "\n",
    "plot_confusion_matrix(Ytest_decoded, y_pred_decoded, labels=class_labels)\n",
    "\n"
   ]
=======
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TabNet)",
   "language": "python",
   "name": "tabnet-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
