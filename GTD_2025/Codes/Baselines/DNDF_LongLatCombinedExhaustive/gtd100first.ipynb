{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from train import main\n",
    "from itertools import product  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:36<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:37<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:35<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  42%|████▏     | 125/300 [00:40<00:56,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 126\n",
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:38<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:34<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:37<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:39<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|██████▏   | 187/300 [00:59<00:35,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 188\n",
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:45<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:38<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  99%|█████████▊| 296/300 [01:34<00:01,  3.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 297\n",
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:45<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:41<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:35<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:44<00:00,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:40<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  62%|██████▏   | 186/300 [01:00<00:36,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 187\n",
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:49<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:41<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  74%|███████▍  | 223/300 [01:12<00:25,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 224\n",
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:51<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:42<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  82%|████████▏ | 245/300 [01:21<00:18,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 246\n",
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.0001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Epochs: 100%|██████████| 300/300 [01:51<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.001\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:42<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.01\n",
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  77%|███████▋  | 230/300 [01:15<00:22,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 231\n",
      "\n",
      "Best hyperparameter configuration:\n",
      "{'n_tree': 30, 'tree_depth': 10, 'batch_size': 512, 'tree_feature_rate': 0.2, 'feat_dropout': 0.1, 'lr': 0.01}\n",
      "Best accuracy: 0.886667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_tree_values = [5, 10, 20, 50, 100, 150, 200, 300]\n",
    "tree_depth_values = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "hidden_dim = [1024, 768]\n",
    "batch_size_values = [256, 512, 1000]\n",
    "#default 0.5\n",
    "tree_feature_rates = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#default 0.3\n",
    "feat_dropouts = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "#default 0.0001\n",
    "lrs = [0.0001, 0.001, 0.01]\n",
    "\n",
    "best_score = 0\n",
    "best_config = {}\n",
    "\n",
    "\n",
    "for n_tree, t_depth, hd, batch_size in product(n_tree_values, tree_depth_values, hidden_dim, batch_size_values):\n",
    "    print(f\"\\nRunning: n_tree={n_tree}, t_depth={t_depth}, hd={hd}, batch_size={batch_size}\")\n",
    "    sys.argv = [\n",
    "        'train.py',\n",
    "        '-dataset', f'gtd{partition}',\n",
    "        '-n_class', '30',\n",
    "        '-gpuid', '0',\n",
    "        '-n_tree', str(n_tree),\n",
    "        '-tree_depth', str(t_depth),\n",
    "        '-batch_size', str(batch_size),\n",
    "        '-hidden_dim', str(hd),\n",
    "        '-epochs', '400',\n",
    "        '-verbose', '0',\n",
    "        #'-tree_feature_rate', str(feature_rate),\n",
    "        #'-feat_dropout', str(dropout),\n",
    "        #'-lr', str(lr),\n",
    "        '-jointly_training',\n",
    "        '-searching', '1'\n",
    "    ]\n",
    "    \n",
    "    complete = main()\n",
    "    print(complete)\n",
    "\n",
    "    # Read best score from file (assumes one run per file)\n",
    "    result_file = f\"results/result_gtd{partition}\"\n",
    "    with open(result_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"Best Accuracy\" in line:\n",
    "                acc = float(line.split()[2])\n",
    "                if acc > best_score:\n",
    "                    best_score = acc\n",
    "                    best_config = {\n",
    "                        'n_tree': n_tree,\n",
    "                        'tree_depth': t_depth,\n",
    "                        'batch_size': batch_size,\n",
    "                        'hidden_dim': hd\n",
    "                        #'tree_feature_rate': feature_rate,\n",
    "                        #'feat_dropout': dropout,\n",
    "                        #'lr': lr\n",
    "                    }\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_config)\n",
    "print(f\"Best accuracy: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gtd100 dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  29%|██▉       | 438/1500 [02:20<05:39,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sys.argv = [\n",
    "    'train.py',\n",
    "    '-dataset', f'gtd{partition}',\n",
    "    '-n_class', '30',\n",
    "    '-gpuid', '0',\n",
    "    '-n_tree', str(best_config['n_tree']),\n",
    "    '-tree_depth', str(best_config['tree_depth']),\n",
    "    '-batch_size', str(best_config['batch_size']),\n",
    "    '-epochs', '1000',\n",
    "    '-verbose', '1',\n",
    "    '-jointly_training'\n",
    "]\"\"\"\n",
    "\n",
    "sys.argv = [\n",
    "        'train.py',\n",
    "        '-dataset', f'gtd{partition}',\n",
    "        '-n_class', '30',\n",
    "        '-gpuid', '0',\n",
    "        '-n_tree', str(best_config['n_tree']),\n",
    "        '-tree_depth', str(best_config['tree_depth']),\n",
    "        '-batch_size', str(best_config['batch_size']),\n",
    "        '-hidden_dim', str(best_config['hidden_dim']),\n",
    "        '-epochs', '1500',\n",
    "        '-verbose', '0',\n",
    "        #'-tree_feature_rate', str(best_config['tree_feature_rate']),\n",
    "        #'-feat_dropout', str(best_config['feat_dropout']),\n",
    "        #'-lr', str(best_config['lr']),\n",
    "        '-jointly_training',\n",
    "        '-searching', '0'\n",
    "    ]\n",
    "\n",
    "best_model, preds, targets, labels, epoch_logs = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       0.00      0.00      0.00        30\n",
      "        African National Congress (South Africa)       0.00      0.00      0.00        30\n",
      "                                Al-Qaida in Iraq       0.13      0.97      0.24        30\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.51      0.77      0.61        30\n",
      "                                      Al-Shabaab       0.00      0.00      0.00        30\n",
      "             Basque Fatherland and Freedom (ETA)       0.06      0.07      0.06        30\n",
      "                                      Boko Haram       0.00      0.00      0.00        30\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.00      0.00      0.00        30\n",
      "       Corsican National Liberation Front (FLNC)       0.00      0.00      0.00        30\n",
      "                       Donetsk People's Republic       0.00      0.00      0.00        30\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.00      0.00      0.00        30\n",
      "                               Fulani extremists       0.21      0.70      0.33        30\n",
      "                 Houthi extremists (Ansar Allah)       0.00      0.00      0.00        30\n",
      "                     Irish Republican Army (IRA)       0.09      0.40      0.15        30\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.00      0.00      0.00        30\n",
      "                  Kurdistan Workers' Party (PKK)       0.00      0.00      0.00        30\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.00      0.00      0.00        30\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       0.00      0.00      0.00        30\n",
      "                                         Maoists       0.00      0.00      0.00        30\n",
      "                               Muslim extremists       0.00      0.00      0.00        30\n",
      "      National Liberation Army of Colombia (ELN)       0.11      0.77      0.20        30\n",
      "                         New People's Army (NPA)       0.00      0.00      0.00        30\n",
      "               Nicaraguan Democratic Force (FDN)       0.14      0.30      0.19        30\n",
      "                                    Palestinians       0.00      0.00      0.00        30\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.00      0.00      0.00        30\n",
      "                               Shining Path (SL)       0.00      0.00      0.00        30\n",
      "                                 Sikh Extremists       0.27      0.77      0.40        30\n",
      "                                         Taliban       0.00      0.00      0.00        30\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.00      0.00      0.00        30\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.00      0.00      0.00        30\n",
      "\n",
      "                                        accuracy                           0.16       900\n",
      "                                       macro avg       0.05      0.16      0.07       900\n",
      "                                    weighted avg       0.05      0.16      0.07       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/conda/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, partition):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix (Partition gtd{partition})\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = f\"results/confusion_matrix_partition_gtd{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition gtd{partition} to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition gtd100 to results/confusion_matrix_partition_gtd100.png\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(targets, preds, labels, partition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
