{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df100.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1790"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_longlat(df):\n",
    "    # Step 1: Create new 'longlat' feature as tuple\n",
    "    df['longlat'] = list(zip(df['longitude'], df['latitude']))\n",
    "\n",
    "    # Step 2: One-hot encode the new 'longlat' feature\n",
    "    longlat_encoded = pd.get_dummies(df['longlat'], prefix='loc')\n",
    "\n",
    "    # Step 3: Drop original longitude and latitude\n",
    "    df = df.drop(columns=['longitude', 'latitude', 'longlat'])\n",
    "\n",
    "    # Step 4: Concatenate the one-hot encoded features\n",
    "    df = pd.concat([df, longlat_encoded], axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 17)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# creates train and test data, first 70% of each group is added to train and remaining 30% to test\n",
    "def handle_leakage(df):\n",
    "    train_frames = []\n",
    "    test_frames = []\n",
    "\n",
    "    split_point = int(len(df) * 0.7)  # 70% for training\n",
    "    train_df = df[:split_point]\n",
    "    test_df = df[split_point:]          \n",
    "\n",
    "    # Shuffle each DataFrame separately\n",
    "    train_df = shuffle(train_df)\n",
    "    test_df = shuffle(test_df)\n",
    "\n",
    "    print(train_df.shape)\n",
    "\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1253, 1805)\n"
     ]
    }
   ],
   "source": [
    "df = encode_longlat(df)\n",
    "traindf, testdf = handle_leakage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1790, 1805)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf.to_csv(\"train100.csv\")\n",
    "testdf.to_csv(\"test100.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
