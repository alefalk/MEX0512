{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from train import main\n",
    "from itertools import product  \n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:53<00:00,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:48<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.0, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:49<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:48<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.1, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  53%|█████▎    | 160/300 [00:57<00:50,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 161\n",
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:49<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:48<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.1, dropout=0.2, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:50<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:48<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.0, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  52%|█████▏    | 157/300 [00:56<00:51,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 158\n",
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:49<00:00,  2.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.1, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:46<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:50<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.2, dropout=0.2, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:46<00:00,  2.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:51<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.0, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  93%|█████████▎| 280/300 [01:40<00:07,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 281\n",
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:51<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:48<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.1, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  49%|████▊     | 146/300 [00:52<00:54,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 147\n",
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.0001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:50<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.001\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:47<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running: feature_rate=0.3, dropout=0.2, lr=0.01\n",
      "Use gtd478 dataset\n",
      "Patience:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs: 100%|██████████| 300/300 [01:46<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameter configuration:\n",
      "{'n_tree': 10, 'tree_depth': 5, 'batch_size': 512, 'tree_feature_rate': 0.1, 'feat_dropout': 0.0, 'lr': 0.01}\n",
      "Best accuracy: 0.86713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#n_tree_values = [5, 10, 15, 20]\n",
    "#tree_depth_values = [3, 5, 10]\n",
    "#batch_size_values = [256, 512, 1000]\n",
    "tree_feature_rates = [0.1, 0.2, 0.3]\n",
    "feat_dropouts = [0.0, 0.1, 0.2]\n",
    "lrs = [0.0001, 0.001, 0.01]\n",
    "\n",
    "best_score = 0\n",
    "best_config = {}\n",
    "\n",
    "for feature_rate, dropout, lr in product(tree_feature_rates, feat_dropouts, lrs):\n",
    "    print(f\"\\nRunning: feature_rate={feature_rate}, dropout={dropout}, lr={lr}\")\n",
    "    sys.argv = [\n",
    "        'train.py',\n",
    "        '-dataset', f'gtd{partition}',\n",
    "        '-n_class', '30',\n",
    "        '-gpuid', '0',\n",
    "        '-n_tree', '10',\n",
    "        '-tree_depth', '5',\n",
    "        '-batch_size', '512',\n",
    "        '-epochs', '300',\n",
    "        '-verbose', '0',\n",
    "        '-tree_feature_rate', str(feature_rate),\n",
    "        '-feat_dropout', str(dropout),\n",
    "        '-lr', str(lr),\n",
    "        '-jointly_training',\n",
    "        '-searching', '1'\n",
    "    ]\n",
    "    \n",
    "    _, _, _, _, _ = main()\n",
    "\n",
    "    # Read best score from file (assumes one run per file)\n",
    "    result_file = f\"results/result_gtd{partition}\"\n",
    "    with open(result_file, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"Best Accuracy\" in line:\n",
    "                acc = float(line.split()[2])\n",
    "                if acc > best_score:\n",
    "                    best_score = acc\n",
    "                    best_config = {\n",
    "                        'n_tree': 10,\n",
    "                        'tree_depth': 5,\n",
    "                        'batch_size': 512,\n",
    "                        'tree_feature_rate': feature_rate,\n",
    "                        'feat_dropout': dropout,\n",
    "                        'lr': lr\n",
    "                    }\n",
    "print(\"\\nBest hyperparameter configuration:\")\n",
    "print(best_config)\n",
    "print(f\"Best accuracy: {best_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use gtd478 dataset\n",
      "Patience:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:   5%|▌         | 78/1500 [00:27<08:35,  2.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epochs:  69%|██████▊   | 1028/1500 [06:10<02:49,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 1029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"sys.argv = [\n",
    "    'train.py',\n",
    "    '-dataset', f'gtd{partition}',\n",
    "    '-n_class', '30',\n",
    "    '-gpuid', '0',\n",
    "    '-n_tree', str(best_config['n_tree']),\n",
    "    '-tree_depth', str(best_config['tree_depth']),\n",
    "    '-batch_size', str(best_config['batch_size']),\n",
    "    '-epochs', '1000',\n",
    "    '-verbose', '1',\n",
    "    '-jointly_training'\n",
    "]\"\"\"\n",
    "\n",
    "sys.argv = [\n",
    "        'train.py',\n",
    "        '-dataset', f'gtd{partition}',\n",
    "        '-n_class', '30',\n",
    "        '-gpuid', '0',\n",
    "        '-n_tree', '10',\n",
    "        '-tree_depth', '5',\n",
    "        '-batch_size', '512',\n",
    "        '-epochs', '1500',\n",
    "        '-verbose', '0',\n",
    "        '-tree_feature_rate', str(best_config['tree_feature_rate']),\n",
    "        '-feat_dropout', str(best_config['feat_dropout']),\n",
    "        '-lr', str(best_config['lr']),\n",
    "        '-jointly_training',\n",
    "        '-searching', '0'\n",
    "    ]\n",
    "\n",
    "best_model, preds, targets, labels, epoch_logs = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       144\n",
      "           1       1.00      1.00      1.00       144\n",
      "           2       0.71      0.66      0.68       144\n",
      "           3       0.86      0.88      0.87       144\n",
      "           4       0.97      0.99      0.98       144\n",
      "           5       0.94      0.98      0.96       144\n",
      "           6       0.97      0.88      0.92       144\n",
      "           7       0.68      0.99      0.81       144\n",
      "           8       0.96      0.95      0.96       144\n",
      "           9       1.00      1.00      1.00       144\n",
      "          10       0.66      0.97      0.79       144\n",
      "          11       0.86      0.97      0.91       144\n",
      "          12       0.86      0.88      0.87       144\n",
      "          13       1.00      1.00      1.00       144\n",
      "          14       0.52      0.58      0.55       144\n",
      "          15       0.81      0.85      0.83       144\n",
      "          16       0.92      1.00      0.96       144\n",
      "          17       0.99      1.00      1.00       144\n",
      "          18       0.95      0.61      0.74       144\n",
      "          19       0.89      0.53      0.66       144\n",
      "          20       0.75      0.99      0.86       144\n",
      "          21       0.98      0.96      0.97       144\n",
      "          22       0.95      0.49      0.65       144\n",
      "          23       0.97      0.96      0.96       144\n",
      "          24       0.98      0.69      0.81       144\n",
      "          25       0.72      0.99      0.83       144\n",
      "          26       0.89      0.90      0.90       144\n",
      "          27       0.66      0.60      0.63       144\n",
      "          28       0.61      0.65      0.63       144\n",
      "          29       0.99      0.60      0.75       144\n",
      "\n",
      "    accuracy                           0.85      4320\n",
      "   macro avg       0.87      0.85      0.85      4320\n",
      "weighted avg       0.87      0.85      0.85      4320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(targets, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels, partition):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(labels)))\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix (Partition gtd{partition})\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    save_path = f\"results/confusion_matrix_partition_gtd{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition gtd{partition} to {save_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition gtd478 to results/confusion_matrix_partition_gtd478.png\n"
     ]
    }
   ],
   "source": [
    "plot_confusion_matrix(targets, preds, labels, partition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
