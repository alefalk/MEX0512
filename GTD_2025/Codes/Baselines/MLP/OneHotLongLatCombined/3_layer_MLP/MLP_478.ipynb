{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../../../data/top30groups/DNDF_OneHotLongLatCombined/train/train{partition}.csv'\n",
    "testpath = f'../../../../../data/top30groups/DNDF_OneHotLongLatCombined/test/test{partition}.csv'\n",
    "\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')\n",
    "\n",
    "if 'attack_date' in traindata.columns:\n",
    "    traindata = traindata.drop(columns=['attack_date'])\n",
    "\n",
    "if 'attack_date' in testdata.columns:\n",
    "    testdata = testdata.drop(columns=['attack_date'])\n",
    "\n",
    "    print(f'shape train data: ', traindata.shape)\n",
    "    print(f'shape test data: ', testdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4320, 12512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10020, 12512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(dftrain, dftest):\n",
    "    Xtrain = dftrain.drop(columns=['gname']).values\n",
    "    Ytrain = dftrain['gname'].values\n",
    "    Xtest = dftest.drop(columns=['gname']).values\n",
    "    Ytest = dftest['gname'].values\n",
    "\n",
    "    # Encode labels as integers\n",
    "    le = LabelEncoder()\n",
    "    Ytrain = le.fit_transform(Ytrain)\n",
    "    Ytest = le.transform(Ytest)\n",
    "\n",
    "    Xtrain = Xtrain.astype(float)\n",
    "    Xtest = Xtest.astype(float)\n",
    "\n",
    "    # Convert to torch tensors and move to GPU\n",
    "    Xtrain = torch.tensor(Xtrain, dtype=torch.float32).to(\"cuda\")\n",
    "    Ytrain = torch.tensor(Ytrain, dtype=torch.long).to(\"cuda\")\n",
    "    Xtest = torch.tensor(Xtest, dtype=torch.float32).to(\"cuda\")\n",
    "    Ytest = torch.tensor(Ytest, dtype=torch.long).to(\"cuda\")\n",
    "\n",
<<<<<<< HEAD
    "    return Xtrain, Ytrain, Xtest, Ytest, le\n"
=======
    "    return Xtrain, Ytrain, Xtest, Ytest, len(le.classes_)\n"
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterSampler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "class MLP3Layer(nn.Module):\n",
    "    def __init__(self, input_dim, h1, h2, h3, output_dim, activation='relu'):\n",
    "        super().__init__()\n",
    "        act_fn = nn.ReLU() if activation == 'relu' else nn.Tanh()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, h1),\n",
    "            act_fn,\n",
    "            nn.Linear(h1, h2),\n",
    "            act_fn,\n",
    "            nn.Linear(h2, h3),\n",
    "            act_fn,\n",
    "            nn.Linear(h3, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def train_model(model, Xtrain, Ytrain, lr, alpha, max_epochs=100):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=alpha)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(Xtrain)\n",
    "        loss = criterion(output, Ytrain)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate_model(model, Xval, Yval):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(Xval).argmax(dim=1)\n",
    "        acc = (pred == Yval).float().mean().item()\n",
    "    return acc\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def find_best_mlp_3layer(Xtrain, Ytrain, num_classes, max_epochs=100):\n",
    "    input_dim = Xtrain.shape[1]\n",
    "\n",
    "    param_grid = {\n",
    "        'h1': [100, 150],\n",
    "        'h2': [50, 100],\n",
    "        'h3': [25, 50],\n",
    "        'activation': ['relu', 'tanh'],\n",
    "        'lr': [0.001, 0.01],\n",
    "        'alpha': [1e-4, 1e-3]\n",
    "    }\n",
    "\n",
    "    best_acc = -1\n",
    "    best_params = None\n",
    "\n",
    "    for params in ParameterGrid(param_grid):\n",
    "        # Manual 80/20 split\n",
    "        indices = torch.randperm(Xtrain.size(0))\n",
    "        split = int(0.8 * len(indices))\n",
    "        train_idx, val_idx = indices[:split], indices[split:]\n",
    "\n",
    "        model = MLP3Layer(\n",
    "            input_dim=input_dim,\n",
    "            h1=params['h1'],\n",
    "            h2=params['h2'],\n",
    "            h3=params['h3'],\n",
    "            output_dim=num_classes,\n",
    "            activation=params['activation']\n",
    "        ).to(\"cuda\")\n",
    "\n",
    "        train_model(model, Xtrain[train_idx], Ytrain[train_idx],\n",
    "                    lr=params['lr'], alpha=params['alpha'], max_epochs=max_epochs)\n",
    "\n",
    "        acc = evaluate_model(model, Xtrain[val_idx], Ytrain[val_idx])\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_params = params\n",
    "\n",
    "    # âœ… Retrain on full data\n",
    "    final_model = MLP3Layer(\n",
    "        input_dim=input_dim,\n",
    "        h1=best_params['h1'],\n",
    "        h2=best_params['h2'],\n",
    "        h3=best_params['h3'],\n",
    "        output_dim=num_classes,\n",
    "        activation=best_params['activation']\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    train_model(final_model, Xtrain, Ytrain,\n",
    "                lr=best_params['lr'], alpha=best_params['alpha'], max_epochs=max_epochs)\n",
    "\n",
    "    print(f\"Best accuracy on validation split: {best_acc * 100:.2f}%\")\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "extended              float64\n",
       "vicinity              float64\n",
       "multiple              float64\n",
       "success               float64\n",
       "suicide               float64\n",
       "                       ...   \n",
       "latitude_55.751377       bool\n",
       "latitude_55.863239       bool\n",
       "latitude_55.864237       bool\n",
       "latitude_59.913869       bool\n",
       "gname                  object\n",
       "Length: 12512, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.dtypes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 9,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Best accuracy on validation split: 62.38%\n",
      "Best hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'h1': 150, 'h2': 50, 'h3': 50, 'lr': 0.01}\n",
      "Accuracy: 63.82%\n"
=======
      "Best accuracy on validation split: 62.92%\n",
      "Best hyperparameters: {'activation': 'tanh', 'alpha': 0.001, 'h1': 150, 'h2': 50, 'h3': 50, 'lr': 0.01}\n",
      "Accuracy: 65.02%\n"
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "Xtrain, Ytrain, Xtest, Ytest, le = split_data(traindata, testdata)\n",
    "best_mlp = find_best_mlp_3layer(Xtrain, Ytrain, 30)\n",
=======
    "Xtrain, Ytrain, Xtest, Ytest, num_classes = split_data(traindata, testdata)\n",
    "best_mlp = find_best_mlp_3layer(Xtrain, Ytrain, num_classes)\n",
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
    "\n",
    "best_mlp.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = best_mlp(Xtest).argmax(dim=1)\n",
    "    acc = (y_pred == Ytest).float().mean().item()\n",
    "    print(f\"Accuracy: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 10,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path = os.path.join(\"results\", f\"gtd{partition}.txt\")\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# Write a string to the file\n",
    "with open(file_path, \"w\") as file:\n",
    "    file.write(str(acc))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_decoded = le.inverse_transform(Ytest.cpu().numpy())\n",
    "y_pred_decoded = le.inverse_transform(y_pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       0.53      0.72      0.61       144\n",
      "        African National Congress (South Africa)       0.78      0.77      0.77       144\n",
      "                                Al-Qaida in Iraq       0.79      0.70      0.74       144\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.32      0.76      0.45       144\n",
      "                                      Al-Shabaab       0.63      0.74      0.68       144\n",
      "             Basque Fatherland and Freedom (ETA)       0.89      0.75      0.82       144\n",
      "                                      Boko Haram       0.80      0.49      0.60       144\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.67      0.38      0.48       144\n",
      "       Corsican National Liberation Front (FLNC)       1.00      0.95      0.98       144\n",
      "                       Donetsk People's Republic       0.95      0.81      0.88       144\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.99      0.83      0.90       144\n",
      "                               Fulani extremists       0.47      0.77      0.58       144\n",
      "                 Houthi extremists (Ansar Allah)       0.87      0.65      0.74       144\n",
      "                     Irish Republican Army (IRA)       0.99      0.86      0.92       144\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.58      0.46      0.51       144\n",
      "                  Kurdistan Workers' Party (PKK)       0.37      0.40      0.39       144\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.89      0.70      0.79       144\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       0.92      0.91      0.91       144\n",
      "                                         Maoists       0.25      0.38      0.30       144\n",
      "                               Muslim extremists       0.78      0.51      0.61       144\n",
      "      National Liberation Army of Colombia (ELN)       0.82      0.61      0.70       144\n",
      "                         New People's Army (NPA)       0.52      0.22      0.31       144\n",
      "               Nicaraguan Democratic Force (FDN)       0.66      0.77      0.71       144\n",
      "                                    Palestinians       0.80      0.87      0.83       144\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.31      0.30      0.30       144\n",
      "                               Shining Path (SL)       0.57      0.48      0.52       144\n",
      "                                 Sikh Extremists       0.94      0.71      0.81       144\n",
      "                                         Taliban       0.46      0.39      0.42       144\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.88      0.62      0.73       144\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.34      0.66      0.45       144\n",
      "\n",
      "                                        accuracy                           0.64      4320\n",
      "                                       macro avg       0.69      0.64      0.65      4320\n",
      "                                    weighted avg       0.69      0.64      0.65      4320\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_decoded, y_pred_decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
=======
   "execution_count": 11,
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP3Layer(\n",
      "  (model): Sequential(\n",
      "    (0): Linear(in_features=12511, out_features=150, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=150, out_features=50, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=50, out_features=30, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(best_mlp)"
   ]
<<<<<<< HEAD
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, labels):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(18, 16))\n",
    "    sns.heatmap(cm_normalized,\n",
    "                annot=True,\n",
    "                fmt=\".2f\",\n",
    "                xticklabels=labels,\n",
    "                yticklabels=labels,\n",
    "                cmap=\"viridis\",\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "    plt.title(f\"Normalized Confusion Matrix (Partition {partition})\", fontsize=18)\n",
    "    plt.xlabel(\"Predicted Label\", fontsize=14)\n",
    "    plt.ylabel(\"True Label\", fontsize=14)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the figure\n",
    "    save_path = f\"results/confusion_matrix_partition_{partition}.png\"\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Saved confusion matrix for partition {partition} to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved confusion matrix for partition 478 to results/confusion_matrix_partition_478.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all unique class labels from the truths\n",
    "class_labels = np.unique(y_true_decoded)\n",
    "\n",
    "plot_confusion_matrix(y_true_decoded, y_pred_decoded, labels=class_labels)\n",
    "\n"
   ]
=======
>>>>>>> f63e82328f0834a7e5a9edc1b09f0142d6c5bb20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
