{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8b7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from build_graph_data import *\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d877870",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 478"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a56371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../data/top30groups/noGeographic/train1/train{partition}.csv'\n",
    "testpath = f'../../../data/top30groups/noGeographic/test1/test{partition}.csv'\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c53a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([traindata, testdata], axis = 0)\n",
    "data = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e017e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset: attacktype1, target1, Nodes: 7888\n",
      "Subset: attacktype1, weaptype1 had too few unique combinations: 40, discarding.\n",
      "Subset: attacktype1, nkill had too few unique combinations: 270, discarding.\n",
      "Subset: target1, weaptype1, Nodes: 7819\n",
      "Subset: target1, nkill, Nodes: 8751\n",
      "Subset: weaptype1, nkill had too few unique combinations: 225, discarding.\n",
      "Subset: attacktype1, target1, weaptype1, Nodes: 8060\n",
      "Subset: attacktype1, target1, nkill, Nodes: 9308\n",
      "Subset: attacktype1, weaptype1, nkill had too few unique combinations: 418, discarding.\n",
      "Subset: target1, weaptype1, nkill, Nodes: 9235\n",
      "Subset: attacktype1, target1, weaptype1, nkill, Nodes: 9484\n",
      "\n",
      "--- Kept Combinations ---\n",
      "Key: attacktype1, target1 | Features: ['attacktype1', 'target1'] | Nodes: 7888\n",
      "Key: target1, weaptype1 | Features: ['target1', 'weaptype1'] | Nodes: 7819\n",
      "Key: target1, nkill | Features: ['target1', 'nkill'] | Nodes: 8751\n",
      "Key: attacktype1, target1, weaptype1 | Features: ['attacktype1', 'target1', 'weaptype1'] | Nodes: 8060\n",
      "Key: attacktype1, target1, nkill | Features: ['attacktype1', 'target1', 'nkill'] | Nodes: 9308\n",
      "Key: target1, weaptype1, nkill | Features: ['target1', 'weaptype1', 'nkill'] | Nodes: 9235\n",
      "Key: attacktype1, target1, weaptype1, nkill | Features: ['attacktype1', 'target1', 'weaptype1', 'nkill'] | Nodes: 9484\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "def create_node_dataframe(data, node_features, label_column='gname'):\n",
    "    relevant_data = data[node_features + [label_column]].copy()\n",
    "    relevant_data['combination'] = list(zip(*(relevant_data[feat] for feat in node_features)))\n",
    "    df_unique = relevant_data.drop_duplicates(subset=['combination'], keep='first').reset_index(drop=True)\n",
    "    return df_unique[['combination', label_column]]\n",
    "\n",
    "# All possible features to try\n",
    "all_features = ['attacktype1', 'target1', 'weaptype1', 'nkill']\n",
    "label_column = 'gname'\n",
    "\n",
    "min_nodes = len(data) * 0.3\n",
    "combination_dfs = {}\n",
    "kept_combinations = []  # To store info about kept subsets\n",
    "\n",
    "for r in range(2, len(all_features) + 1):\n",
    "    for feature_subset in itertools.combinations(all_features, r):\n",
    "        feature_subset = list(feature_subset)\n",
    "        df_filtered = create_node_dataframe(data, feature_subset, label_column=label_column)\n",
    "\n",
    "        n_nodes = df_filtered.shape[0]\n",
    "        key = \", \".join(feature_subset)\n",
    "\n",
    "        if n_nodes >= min_nodes:\n",
    "            combination_dfs[key] = df_filtered\n",
    "            kept_combinations.append((key, feature_subset, n_nodes))\n",
    "            print(f\"Subset: {key}, Nodes: {n_nodes}\")\n",
    "        else:\n",
    "            print(f\"Subset: {key} had too few unique combinations: {n_nodes}, discarding.\")\n",
    "\n",
    "# After the loop, print a summary of kept combinations\n",
    "print(\"\\n--- Kept Combinations ---\")\n",
    "for key, features, n_nodes in kept_combinations:\n",
    "    print(f\"Key: {key} | Features: {features} | Nodes: {n_nodes}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "021b498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tuple_if_needed(val):\n",
    "    if isinstance(val, str):\n",
    "        return ast.literal_eval(val)\n",
    "    return val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "105297b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class PyTorchGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "716ac4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def run_epoch(model, data, labels, mask, optimizer=None):\n",
    "    is_training = optimizer is not None\n",
    "    if is_training:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    loss = loss_fn(out[mask], labels[mask])\n",
    "\n",
    "    if is_training:\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Accuracy\n",
    "    pred = out[mask].argmax(dim=1)\n",
    "    acc = (pred == labels[mask]).float().mean().item()\n",
    "    return acc, loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3ab8545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "if not os.path.isdir(f\"Results\"):\n",
    "    os.mkdir(f\"Results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d425d825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing feature subset: attacktype1, target1 ---\n",
      "Number of total nodes (unique coordinates): 7888\n",
      "Number of unique labels in this set: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Acc: 0.0319 | Test Acc: 0.0413 | Train Loss: 62.1984 | Test Loss: 68.3599\n",
      "Epoch 200 | Train Acc: 0.0477 | Test Acc: 0.0468 | Train Loss: 34.5458 | Test Loss: 33.2841\n",
      "Epoch 300 | Train Acc: 0.0548 | Test Acc: 0.0354 | Train Loss: 22.9506 | Test Loss: 21.8129\n",
      "Epoch 400 | Train Acc: 0.0798 | Test Acc: 0.0453 | Train Loss: 5.5510 | Test Loss: 5.9952\n",
      "Epoch 500 | Train Acc: 0.1648 | Test Acc: 0.1028 | Train Loss: 2.9769 | Test Loss: 3.0779\n",
      "Epoch 600 | Train Acc: 0.1663 | Test Acc: 0.1322 | Train Loss: 2.8924 | Test Loss: 2.9841\n",
      "Epoch 700 | Train Acc: 0.1763 | Test Acc: 0.1374 | Train Loss: 2.8575 | Test Loss: 2.9556\n",
      "Epoch 800 | Train Acc: 0.1967 | Test Acc: 0.1378 | Train Loss: 2.8265 | Test Loss: 2.9309\n",
      "Epoch 900 | Train Acc: 0.0677 | Test Acc: 0.0597 | Train Loss: 19.0830 | Test Loss: 19.3458\n",
      "Epoch 1000 | Train Acc: 0.0698 | Test Acc: 0.0862 | Train Loss: 6.1918 | Test Loss: 6.4017\n",
      "Epoch 1100 | Train Acc: 0.2194 | Test Acc: 0.2033 | Train Loss: 2.7770 | Test Loss: 2.8938\n",
      "Epoch 1200 | Train Acc: 0.2430 | Test Acc: 0.2077 | Train Loss: 2.7233 | Test Loss: 2.8522\n",
      "Epoch 1300 | Train Acc: 0.2444 | Test Acc: 0.2147 | Train Loss: 2.6887 | Test Loss: 2.8260\n",
      "Epoch 1400 | Train Acc: 0.2273 | Test Acc: 0.2070 | Train Loss: 2.6737 | Test Loss: 2.8059\n",
      "Epoch 1500 | Train Acc: 0.2362 | Test Acc: 0.1867 | Train Loss: 2.7260 | Test Loss: 2.8504\n",
      "Epoch 1600 | Train Acc: 0.1861 | Test Acc: 0.1374 | Train Loss: 3.1669 | Test Loss: 3.3688\n",
      "Epoch 1700 | Train Acc: 0.1393 | Test Acc: 0.1746 | Train Loss: 8.3321 | Test Loss: 4.4493\n",
      "Epoch 1800 | Train Acc: 0.1854 | Test Acc: 0.1823 | Train Loss: 2.7054 | Test Loss: 2.9175\n",
      "Epoch 1900 | Train Acc: 0.2733 | Test Acc: 0.2317 | Train Loss: 2.5948 | Test Loss: 2.7361\n",
      "Epoch 2000 | Train Acc: 0.2264 | Test Acc: 0.2147 | Train Loss: 2.6007 | Test Loss: 2.7508\n",
      "Best test accuracy for attacktype1, target1: 0.2652 at epoch 1871\n",
      "\n",
      "--- Processing feature subset: target1, weaptype1 ---\n",
      "Number of total nodes (unique coordinates): 7819\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0743 | Test Acc: 0.0908 | Train Loss: 17.9770 | Test Loss: 17.7677\n",
      "Epoch 200 | Train Acc: 0.0796 | Test Acc: 0.0484 | Train Loss: 3.4657 | Test Loss: 3.7240\n",
      "Epoch 300 | Train Acc: 0.1370 | Test Acc: 0.0997 | Train Loss: 2.9146 | Test Loss: 3.2088\n",
      "Epoch 400 | Train Acc: 0.1680 | Test Acc: 0.1027 | Train Loss: 2.8559 | Test Loss: 3.1224\n",
      "Epoch 500 | Train Acc: 0.2431 | Test Acc: 0.1619 | Train Loss: 2.8041 | Test Loss: 3.0379\n",
      "Epoch 600 | Train Acc: 0.0497 | Test Acc: 0.0421 | Train Loss: 27.2656 | Test Loss: 27.3205\n",
      "Epoch 700 | Train Acc: 0.0941 | Test Acc: 0.0971 | Train Loss: 3.0436 | Test Loss: 3.1262\n",
      "Epoch 800 | Train Acc: 0.2137 | Test Acc: 0.1771 | Train Loss: 2.8704 | Test Loss: 2.9498\n",
      "Epoch 900 | Train Acc: 0.2061 | Test Acc: 0.1690 | Train Loss: 2.8177 | Test Loss: 2.9023\n",
      "Epoch 1000 | Train Acc: 0.2378 | Test Acc: 0.1909 | Train Loss: 2.7747 | Test Loss: 2.8649\n",
      "Epoch 1100 | Train Acc: 0.2392 | Test Acc: 0.1909 | Train Loss: 2.7368 | Test Loss: 2.8333\n",
      "Epoch 1200 | Train Acc: 0.2429 | Test Acc: 0.1932 | Train Loss: 2.7032 | Test Loss: 2.8067\n",
      "Epoch 1300 | Train Acc: 0.2408 | Test Acc: 0.1999 | Train Loss: 2.6936 | Test Loss: 2.8000\n",
      "Epoch 1400 | Train Acc: 0.2299 | Test Acc: 0.1611 | Train Loss: 2.7504 | Test Loss: 2.8738\n",
      "Epoch 1500 | Train Acc: 0.2679 | Test Acc: 0.1846 | Train Loss: 2.7083 | Test Loss: 2.7908\n",
      "Epoch 1600 | Train Acc: 0.2265 | Test Acc: 0.1958 | Train Loss: 2.6872 | Test Loss: 2.7749\n",
      "Epoch 1700 | Train Acc: 0.1577 | Test Acc: 0.2244 | Train Loss: 3.4685 | Test Loss: 3.1126\n",
      "Epoch 1800 | Train Acc: 0.1614 | Test Acc: 0.2159 | Train Loss: 2.8033 | Test Loss: 2.7380\n",
      "Epoch 1900 | Train Acc: 0.2367 | Test Acc: 0.1623 | Train Loss: 2.6136 | Test Loss: 2.7600\n",
      "Epoch 2000 | Train Acc: 0.2485 | Test Acc: 0.2132 | Train Loss: 2.5711 | Test Loss: 2.7181\n",
      "Best test accuracy for target1, weaptype1: 0.2739 at epoch 1841\n",
      "\n",
      "--- Processing feature subset: target1, nkill ---\n",
      "Number of total nodes (unique coordinates): 8751\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0449 | Test Acc: 0.0409 | Train Loss: 54.1637 | Test Loss: 57.4838\n",
      "Epoch 200 | Train Acc: 0.0366 | Test Acc: 0.0459 | Train Loss: 33.9537 | Test Loss: 38.4663\n",
      "Epoch 300 | Train Acc: 0.0571 | Test Acc: 0.0476 | Train Loss: 20.0908 | Test Loss: 20.5562\n",
      "Epoch 400 | Train Acc: 0.0399 | Test Acc: 0.0778 | Train Loss: 8.9097 | Test Loss: 8.6767\n",
      "Epoch 500 | Train Acc: 0.0548 | Test Acc: 0.0798 | Train Loss: 9.7933 | Test Loss: 9.9786\n",
      "Epoch 600 | Train Acc: 0.0886 | Test Acc: 0.0845 | Train Loss: 7.8011 | Test Loss: 7.4489\n",
      "Epoch 700 | Train Acc: 0.1497 | Test Acc: 0.1220 | Train Loss: 3.0784 | Test Loss: 3.4046\n",
      "Epoch 800 | Train Acc: 0.1487 | Test Acc: 0.1550 | Train Loss: 2.9799 | Test Loss: 3.2489\n",
      "Epoch 900 | Train Acc: 0.1554 | Test Acc: 0.1570 | Train Loss: 2.9143 | Test Loss: 3.1492\n",
      "Epoch 1000 | Train Acc: 0.1791 | Test Acc: 0.1610 | Train Loss: 2.8474 | Test Loss: 3.0569\n",
      "Epoch 1100 | Train Acc: 0.2160 | Test Acc: 0.1566 | Train Loss: 2.7713 | Test Loss: 2.9442\n",
      "Epoch 1200 | Train Acc: 0.2160 | Test Acc: 0.1749 | Train Loss: 2.7661 | Test Loss: 2.9108\n",
      "Epoch 1300 | Train Acc: 0.2135 | Test Acc: 0.1806 | Train Loss: 2.7589 | Test Loss: 2.8937\n",
      "Epoch 1400 | Train Acc: 0.1071 | Test Acc: 0.1104 | Train Loss: 12.6989 | Test Loss: 12.7848\n",
      "Epoch 1500 | Train Acc: 0.1464 | Test Acc: 0.1550 | Train Loss: 3.5333 | Test Loss: 3.6262\n",
      "Epoch 1600 | Train Acc: 0.2505 | Test Acc: 0.2255 | Train Loss: 2.7653 | Test Loss: 2.8741\n",
      "Epoch 1700 | Train Acc: 0.2539 | Test Acc: 0.2052 | Train Loss: 2.7537 | Test Loss: 2.8678\n",
      "Epoch 1800 | Train Acc: 0.2545 | Test Acc: 0.2072 | Train Loss: 2.7444 | Test Loss: 2.8608\n",
      "Epoch 1900 | Train Acc: 0.2278 | Test Acc: 0.2055 | Train Loss: 2.7708 | Test Loss: 2.8695\n",
      "Epoch 2000 | Train Acc: 0.2295 | Test Acc: 0.2042 | Train Loss: 2.8066 | Test Loss: 2.9296\n",
      "Best test accuracy for target1, nkill: 0.2474 at epoch 1605\n",
      "\n",
      "--- Processing feature subset: attacktype1, target1, weaptype1 ---\n",
      "Number of total nodes (unique coordinates): 8060\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0523 | Test Acc: 0.0385 | Train Loss: 14.4890 | Test Loss: 14.5754\n",
      "Epoch 200 | Train Acc: 0.0874 | Test Acc: 0.0608 | Train Loss: 4.2938 | Test Loss: 4.3436\n",
      "Epoch 300 | Train Acc: 0.1758 | Test Acc: 0.1299 | Train Loss: 3.5594 | Test Loss: 3.6326\n",
      "Epoch 400 | Train Acc: 0.1936 | Test Acc: 0.1421 | Train Loss: 3.1825 | Test Loss: 3.2720\n",
      "Epoch 500 | Train Acc: 0.2068 | Test Acc: 0.1457 | Train Loss: 2.9048 | Test Loss: 3.0357\n",
      "Epoch 600 | Train Acc: 0.1257 | Test Acc: 0.1220 | Train Loss: 4.8007 | Test Loss: 4.0251\n",
      "Epoch 700 | Train Acc: 0.1838 | Test Acc: 0.1454 | Train Loss: 3.1894 | Test Loss: 3.6609\n",
      "Epoch 800 | Train Acc: 0.2455 | Test Acc: 0.2119 | Train Loss: 2.6876 | Test Loss: 2.8352\n",
      "Epoch 900 | Train Acc: 0.2446 | Test Acc: 0.2022 | Train Loss: 2.6563 | Test Loss: 2.8063\n",
      "Epoch 1000 | Train Acc: 0.2354 | Test Acc: 0.1864 | Train Loss: 2.6529 | Test Loss: 2.7946\n",
      "Epoch 1100 | Train Acc: 0.2445 | Test Acc: 0.1364 | Train Loss: 2.9371 | Test Loss: 3.1452\n",
      "Epoch 1200 | Train Acc: 0.1381 | Test Acc: 0.1331 | Train Loss: 3.2082 | Test Loss: 3.2471\n",
      "Epoch 1300 | Train Acc: 0.2422 | Test Acc: 0.2173 | Train Loss: 2.6089 | Test Loss: 2.7313\n",
      "Epoch 1400 | Train Acc: 0.2808 | Test Acc: 0.2497 | Train Loss: 2.5333 | Test Loss: 2.6931\n",
      "Epoch 1500 | Train Acc: 0.2847 | Test Acc: 0.2476 | Train Loss: 2.5091 | Test Loss: 2.6745\n",
      "Epoch 1600 | Train Acc: 0.2984 | Test Acc: 0.2713 | Train Loss: 2.4666 | Test Loss: 2.6510\n",
      "Epoch 1700 | Train Acc: 0.1818 | Test Acc: 0.1439 | Train Loss: 4.1080 | Test Loss: 4.1492\n",
      "Epoch 1800 | Train Acc: 0.2088 | Test Acc: 0.1364 | Train Loss: 3.4012 | Test Loss: 4.6432\n",
      "Epoch 1900 | Train Acc: 0.2630 | Test Acc: 0.2530 | Train Loss: 2.4324 | Test Loss: 2.6640\n",
      "Epoch 2000 | Train Acc: 0.3349 | Test Acc: 0.2969 | Train Loss: 2.3850 | Test Loss: 2.5853\n",
      "Best test accuracy for attacktype1, target1, weaptype1: 0.3246 at epoch 1661\n",
      "\n",
      "--- Processing feature subset: attacktype1, target1, nkill ---\n",
      "Number of total nodes (unique coordinates): 9308\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0359 | Test Acc: 0.0466 | Train Loss: 56.0412 | Test Loss: 52.5073\n",
      "Epoch 200 | Train Acc: 0.0375 | Test Acc: 0.0275 | Train Loss: 35.0384 | Test Loss: 30.5692\n",
      "Epoch 300 | Train Acc: 0.0459 | Test Acc: 0.0444 | Train Loss: 21.9554 | Test Loss: 21.1320\n",
      "Epoch 400 | Train Acc: 0.0532 | Test Acc: 0.0363 | Train Loss: 18.6328 | Test Loss: 16.7130\n",
      "Epoch 500 | Train Acc: 0.0760 | Test Acc: 0.0547 | Train Loss: 7.4660 | Test Loss: 7.8966\n",
      "Epoch 600 | Train Acc: 0.1502 | Test Acc: 0.0819 | Train Loss: 2.9745 | Test Loss: 3.0771\n",
      "Epoch 700 | Train Acc: 0.1800 | Test Acc: 0.1085 | Train Loss: 2.9384 | Test Loss: 3.0413\n",
      "Epoch 800 | Train Acc: 0.1740 | Test Acc: 0.1247 | Train Loss: 2.9171 | Test Loss: 3.0255\n",
      "Epoch 900 | Train Acc: 0.1807 | Test Acc: 0.1291 | Train Loss: 2.8985 | Test Loss: 3.0119\n",
      "Epoch 1000 | Train Acc: 0.1872 | Test Acc: 0.1425 | Train Loss: 2.8812 | Test Loss: 2.9999\n",
      "Epoch 1100 | Train Acc: 0.1779 | Test Acc: 0.1272 | Train Loss: 2.8826 | Test Loss: 3.0073\n",
      "Epoch 1200 | Train Acc: 0.1069 | Test Acc: 0.0803 | Train Loss: 14.0599 | Test Loss: 14.2858\n",
      "Epoch 1300 | Train Acc: 0.0732 | Test Acc: 0.0713 | Train Loss: 4.9952 | Test Loss: 4.8708\n",
      "Epoch 1400 | Train Acc: 0.1793 | Test Acc: 0.1494 | Train Loss: 2.8442 | Test Loss: 2.9764\n",
      "Epoch 1500 | Train Acc: 0.2277 | Test Acc: 0.1885 | Train Loss: 2.7992 | Test Loss: 2.9328\n",
      "Epoch 1600 | Train Acc: 0.2372 | Test Acc: 0.1994 | Train Loss: 2.7712 | Test Loss: 2.8990\n",
      "Epoch 1700 | Train Acc: 0.2420 | Test Acc: 0.2016 | Train Loss: 2.7541 | Test Loss: 2.8842\n",
      "Epoch 1800 | Train Acc: 0.2447 | Test Acc: 0.2057 | Train Loss: 2.7378 | Test Loss: 2.8697\n",
      "Epoch 1900 | Train Acc: 0.2592 | Test Acc: 0.2169 | Train Loss: 2.7191 | Test Loss: 2.8550\n",
      "Epoch 2000 | Train Acc: 0.1853 | Test Acc: 0.1901 | Train Loss: 2.7860 | Test Loss: 2.8989\n",
      "Best test accuracy for attacktype1, target1, nkill: 0.2232 at epoch 1958\n",
      "\n",
      "--- Processing feature subset: target1, weaptype1, nkill ---\n",
      "Number of total nodes (unique coordinates): 9235\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0562 | Test Acc: 0.0521 | Train Loss: 27.0900 | Test Loss: 30.3556\n",
      "Epoch 200 | Train Acc: 0.0846 | Test Acc: 0.0499 | Train Loss: 21.7290 | Test Loss: 23.5625\n",
      "Epoch 300 | Train Acc: 0.0459 | Test Acc: 0.1134 | Train Loss: 16.3319 | Test Loss: 17.4683\n",
      "Epoch 400 | Train Acc: 0.0880 | Test Acc: 0.0938 | Train Loss: 9.1832 | Test Loss: 8.7817\n",
      "Epoch 500 | Train Acc: 0.0957 | Test Acc: 0.0815 | Train Loss: 3.9157 | Test Loss: 4.0417\n",
      "Epoch 600 | Train Acc: 0.0931 | Test Acc: 0.0780 | Train Loss: 6.3451 | Test Loss: 5.7653\n",
      "Epoch 700 | Train Acc: 0.1728 | Test Acc: 0.1162 | Train Loss: 3.0313 | Test Loss: 3.1884\n",
      "Epoch 800 | Train Acc: 0.1829 | Test Acc: 0.1314 | Train Loss: 2.8627 | Test Loss: 2.9695\n",
      "Epoch 900 | Train Acc: 0.1838 | Test Acc: 0.1330 | Train Loss: 2.8351 | Test Loss: 2.9453\n",
      "Epoch 1000 | Train Acc: 0.1961 | Test Acc: 0.1579 | Train Loss: 2.7931 | Test Loss: 2.9133\n",
      "Epoch 1100 | Train Acc: 0.2169 | Test Acc: 0.1617 | Train Loss: 2.7605 | Test Loss: 2.8970\n",
      "Epoch 1200 | Train Acc: 0.2215 | Test Acc: 0.1753 | Train Loss: 2.7439 | Test Loss: 2.8859\n",
      "Epoch 1300 | Train Acc: 0.1524 | Test Acc: 0.1172 | Train Loss: 10.1274 | Test Loss: 11.0628\n",
      "Epoch 1400 | Train Acc: 0.1710 | Test Acc: 0.1532 | Train Loss: 2.8677 | Test Loss: 2.9677\n",
      "Epoch 1500 | Train Acc: 0.1525 | Test Acc: 0.1598 | Train Loss: 2.8552 | Test Loss: 2.9752\n",
      "Epoch 1600 | Train Acc: 0.2248 | Test Acc: 0.1744 | Train Loss: 2.7226 | Test Loss: 2.8513\n",
      "Epoch 1700 | Train Acc: 0.2291 | Test Acc: 0.1775 | Train Loss: 2.7015 | Test Loss: 2.8289\n",
      "Epoch 1800 | Train Acc: 0.2493 | Test Acc: 0.1886 | Train Loss: 2.6847 | Test Loss: 2.8077\n",
      "Epoch 1900 | Train Acc: 0.2698 | Test Acc: 0.2028 | Train Loss: 2.6684 | Test Loss: 2.7968\n",
      "Epoch 2000 | Train Acc: 0.2449 | Test Acc: 0.1965 | Train Loss: 2.6264 | Test Loss: 2.7820\n",
      "Best test accuracy for target1, weaptype1, nkill: 0.2217 at epoch 1974\n",
      "\n",
      "--- Processing feature subset: attacktype1, target1, weaptype1, nkill ---\n",
      "Number of total nodes (unique coordinates): 9484\n",
      "Number of unique labels in this set: 30\n",
      "Epoch 100 | Train Acc: 0.0620 | Test Acc: 0.0416 | Train Loss: 9.8900 | Test Loss: 9.7237\n",
      "Epoch 200 | Train Acc: 0.0562 | Test Acc: 0.0496 | Train Loss: 9.5392 | Test Loss: 9.4332\n",
      "Epoch 300 | Train Acc: 0.0847 | Test Acc: 0.0728 | Train Loss: 4.8282 | Test Loss: 4.6731\n",
      "Epoch 400 | Train Acc: 0.0931 | Test Acc: 0.1014 | Train Loss: 3.1534 | Test Loss: 3.2791\n",
      "Epoch 500 | Train Acc: 0.0773 | Test Acc: 0.0503 | Train Loss: 4.9868 | Test Loss: 5.0134\n",
      "Epoch 600 | Train Acc: 0.0962 | Test Acc: 0.1104 | Train Loss: 4.2063 | Test Loss: 4.4370\n",
      "Epoch 700 | Train Acc: 0.1878 | Test Acc: 0.1640 | Train Loss: 2.8038 | Test Loss: 3.0202\n",
      "Epoch 800 | Train Acc: 0.1646 | Test Acc: 0.1903 | Train Loss: 2.8159 | Test Loss: 3.0178\n",
      "Epoch 900 | Train Acc: 0.1756 | Test Acc: 0.1360 | Train Loss: 3.2926 | Test Loss: 3.4405\n",
      "Epoch 1000 | Train Acc: 0.1730 | Test Acc: 0.1748 | Train Loss: 3.6873 | Test Loss: 3.3069\n",
      "Epoch 1100 | Train Acc: 0.2179 | Test Acc: 0.1788 | Train Loss: 2.6826 | Test Loss: 2.8975\n",
      "Epoch 1200 | Train Acc: 0.2147 | Test Acc: 0.1921 | Train Loss: 2.7123 | Test Loss: 2.9411\n",
      "Epoch 1300 | Train Acc: 0.2247 | Test Acc: 0.1745 | Train Loss: 2.6902 | Test Loss: 2.9523\n",
      "Epoch 1400 | Train Acc: 0.1731 | Test Acc: 0.1243 | Train Loss: 3.6065 | Test Loss: 3.9355\n",
      "Epoch 1500 | Train Acc: 0.1839 | Test Acc: 0.1557 | Train Loss: 3.1481 | Test Loss: 3.4904\n",
      "Epoch 1600 | Train Acc: 0.2251 | Test Acc: 0.1557 | Train Loss: 2.8049 | Test Loss: 3.2925\n",
      "Epoch 1700 | Train Acc: 0.2473 | Test Acc: 0.2063 | Train Loss: 2.6165 | Test Loss: 2.8995\n",
      "Epoch 1800 | Train Acc: 0.2632 | Test Acc: 0.2260 | Train Loss: 2.5687 | Test Loss: 2.8705\n",
      "Epoch 1900 | Train Acc: 0.2623 | Test Acc: 0.2035 | Train Loss: 2.5888 | Test Loss: 2.9073\n",
      "Epoch 2000 | Train Acc: 0.2702 | Test Acc: 0.1875 | Train Loss: 2.6609 | Test Loss: 3.0527\n",
      "Best test accuracy for attacktype1, target1, weaptype1, nkill: 0.2581 at epoch 1549\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import ast\n",
    "from torch_geometric.data import Data\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Ensure results directory exists\n",
    "os.makedirs(\"Results\", exist_ok=True)\n",
    "\n",
    "output_path = f\"Results/gcn_{partition}.txt\"\n",
    "\n",
    "# Initialize results and clear output file\n",
    "results = {}\n",
    "with open(output_path, \"w\") as f:\n",
    "    f.write(\"Subset\\tTest Accuracy\\tEpoch\\tFeatures Used\\n\")\n",
    "\n",
    "# Loop through each feature combination\n",
    "for key, df_unique in combination_dfs.items():\n",
    "    print(f\"\\n--- Processing feature subset: {key} ---\")\n",
    "\n",
    "    # Ensure tuple format\n",
    "    df_unique = df_unique.copy()\n",
    "    df_unique['combination'] = df_unique['combination'].apply(to_tuple_if_needed)\n",
    "\n",
    "    # Build coord_to_index\n",
    "    coord_to_index = {row['combination']: i for i, row in df_unique.iterrows()}\n",
    "\n",
    "    # Build graph data\n",
    "    adj_matrix, feature_matrix, label_index = build_graph_data(df_unique, coord_to_index)\n",
    "\n",
    "    # Get original data mapped to current node set\n",
    "    features_used = key.split(', ')\n",
    "    full_data = data[features_used + ['gname']].copy()\n",
    "    full_data['combination'] = list(zip(*(full_data[feat] for feat in features_used)))\n",
    "    full_data['combination'] = full_data['combination'].apply(to_tuple_if_needed)\n",
    "    full_data = full_data[full_data['combination'].isin(coord_to_index)]\n",
    "\n",
    "    # Split into train/test\n",
    "    split_point = int(0.7 * len(full_data))\n",
    "    train_df = full_data[:split_point]\n",
    "    test_df = full_data[split_point:]\n",
    "\n",
    "    # Feature matrix\n",
    "    coords = np.array(list(coord_to_index.keys()), dtype=np.float32)\n",
    "    x = torch.tensor(coords, dtype=torch.float32)\n",
    "\n",
    "    # Label and mask tensors\n",
    "    num_nodes = x.shape[0]\n",
    "    y = torch.full((num_nodes,), -1, dtype=torch.long)\n",
    "    train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "\n",
    "    for _, row in train_df.iterrows():\n",
    "        idx = coord_to_index[row['combination']]\n",
    "        y[idx] = label_index[row['gname']]\n",
    "        train_mask[idx] = True\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        idx = coord_to_index[row['combination']]\n",
    "        y[idx] = label_index[row['gname']]\n",
    "        test_mask[idx] = True\n",
    "\n",
    "    # Graph edges\n",
    "    A_coo = coo_matrix(adj_matrix)\n",
    "    edge_index = torch.tensor(np.vstack((A_coo.row, A_coo.col)), dtype=torch.long)\n",
    "\n",
    "    # Build graph object\n",
    "    data_obj = Data(x=x, edge_index=edge_index)\n",
    "\n",
    "    # Model and optimizer\n",
    "    model = PyTorchGCN(in_channels=x.shape[1], hidden_channels=16, num_classes=len(label_index))\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    # Training loop\n",
    "    max_test_acc = 0\n",
    "    max_test_epoch = -1\n",
    "    for epoch in range(2000):\n",
    "        train_acc, train_loss = run_epoch(model, data_obj, y, train_mask, optimizer)\n",
    "        test_acc, test_loss = run_epoch(model, data_obj, y, test_mask)\n",
    "        if test_acc > max_test_acc:\n",
    "            max_test_acc = test_acc\n",
    "            max_test_epoch = epoch + 1\n",
    "        if (epoch + 1) % 100 == 0 or epoch == 1999:\n",
    "            print(f\"Epoch {epoch+1} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    print(f\"Best test accuracy for {key}: {max_test_acc:.4f} at epoch {max_test_epoch}\")\n",
    "    results[key] = max_test_acc\n",
    "\n",
    "    # Append result to summary file\n",
    "    with open(output_path, \"a\") as f:\n",
    "        f.write(f\"Subset: {key}\\n\")\n",
    "        f.write(f\"Best test Acc: {max_test_acc:.4f}\\n\")\n",
    "        f.write(f\"Best epoch: {max_test_epoch}\\n\")\n",
    "        f.write(f\"{'-' * 37}\\n\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
