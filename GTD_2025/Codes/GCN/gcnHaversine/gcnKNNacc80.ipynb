{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7182b9a7",
   "metadata": {},
   "source": [
    "# Denna är inte samma som efterföjnade, kika på gtd200 osv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec8b7c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import networkx as nx\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from build_graph_data import *\n",
    "from collections import Counter\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0152b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a56371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = f'../../../data/top30groups/LongLatCombined/train1/train{partition}.csv'\n",
    "testpath = f'../../../data/top30groups/LongLatCombined/test1/test{partition}.csv'\n",
    "traindata = pd.read_csv(trainpath, encoding='ISO-8859-1')\n",
    "testdata = pd.read_csv(testpath, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3d0e61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['extended', 'latitude', 'longitude', 'vicinity', 'multiple', 'success',\n",
       "       'suicide', 'attacktype1', 'targtype1', 'target1', 'individual',\n",
       "       'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traindata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c53a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([traindata, testdata], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccd140f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 16)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e407a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb2029e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['extended', 'latitude', 'longitude', 'vicinity', 'multiple', 'success',\n",
       "       'suicide', 'attacktype1', 'targtype1', 'target1', 'individual',\n",
       "       'weaptype1', 'nkill', 'property', 'ishostkid', 'gname'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e017e0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries before dropping long/lat duplicates:  (3000, 16)\n",
      "Index(['gname', 'longlat'], dtype='object')\n",
      "Entries after dropping long/lat duplicates (#Nodes):  (3000, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_16451/345096426.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['longlat'] = list(zip(data['longitude'], data['latitude']))\n"
     ]
    }
   ],
   "source": [
    "# Filter dataset to only contain unique coordinates\n",
    "print(\"Entries before dropping long/lat duplicates: \", data.shape)\n",
    "\n",
    "#data.sort_values(by=['longitude', 'latitude', 'attack_date'], inplace=True)\n",
    "\n",
    "# Keep only relevant columns\n",
    "data = data[['longitude', 'latitude', 'gname']]\n",
    "# Drop duplicates based on location, keep the earliest attack\n",
    "data['longlat'] = list(zip(data['longitude'], data['latitude']))\n",
    "df_unique = data.copy()\n",
    "\n",
    "df_unique = df_unique.drop(columns=['longitude', 'latitude'])\n",
    "print(df_unique.columns)\n",
    "print(\"Entries after dropping long/lat duplicates (#Nodes): \", df_unique.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e144090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gname\n",
       "Shining Path (SL)                                   100\n",
       "Abu Sayyaf Group (ASG)                              100\n",
       "Liberation Tigers of Tamil Eelam (LTTE)             100\n",
       "Revolutionary Armed Forces of Colombia (FARC)       100\n",
       "Communist Party of India - Maoist (CPI-Maoist)      100\n",
       "National Liberation Army of Colombia (ELN)          100\n",
       "African National Congress (South Africa)            100\n",
       "Nicaraguan Democratic Force (FDN)                   100\n",
       "Basque Fatherland and Freedom (ETA)                 100\n",
       "New People's Army (NPA)                             100\n",
       "Palestinians                                        100\n",
       "Houthi extremists (Ansar Allah)                     100\n",
       "Kurdistan Workers' Party (PKK)                      100\n",
       "Fulani extremists                                   100\n",
       "Al-Qaida in Iraq                                    100\n",
       "Al-Qaida in the Arabian Peninsula (AQAP)            100\n",
       "Sikh Extremists                                     100\n",
       "Manuel Rodriguez Patriotic Front (FPMR)             100\n",
       "Irish Republican Army (IRA)                         100\n",
       "Maoists                                             100\n",
       "Tupac Amaru Revolutionary Movement (MRTA)           100\n",
       "Islamic State of Iraq and the Levant (ISIL)         100\n",
       "Taliban                                             100\n",
       "Corsican National Liberation Front (FLNC)           100\n",
       "Donetsk People's Republic                           100\n",
       "Farabundo Marti National Liberation Front (FMLN)    100\n",
       "Al-Shabaab                                          100\n",
       "Tehrik-i-Taliban Pakistan (TTP)                     100\n",
       "Boko Haram                                          100\n",
       "Muslim extremists                                   100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique[\"gname\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc1aa2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_point = int(0.7 * len(df_unique))\n",
    "train_df = df_unique[:split_point]\n",
    "test_df = df_unique[split_point:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "713fede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df_unique['label'] = le.fit_transform(df_unique['gname'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09a565c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique['longitude'], df_unique['latitude'] = zip(*df_unique['longlat'])\n",
    "coords = df_unique[['longitude', 'latitude']].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features = scaler.fit_transform(coords)  # shape: [num_nodes, 2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7aea3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k = 5  # Number of neighbors per node\n",
    "nbrs = NearestNeighbors(n_neighbors=k + 1, algorithm='ball_tree').fit(features)\n",
    "_, indices = nbrs.kneighbors(features)\n",
    "\n",
    "edges = []\n",
    "for i in range(len(df_unique)):\n",
    "    for j in indices[i][1:]:  # skip self-loop\n",
    "        edges.append((i, j))\n",
    "        edges.append((j, i))  # undirected graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63fee3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(df_unique)\n",
    "y = df_unique['label'].values\n",
    "train_mask = np.zeros(num_nodes, dtype=bool)\n",
    "test_mask = np.zeros(num_nodes, dtype=bool)\n",
    "\n",
    "train_indices = train_df.index\n",
    "test_indices = test_df.index\n",
    "\n",
    "train_mask[train_indices] = True\n",
    "test_mask[test_indices] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "25d50551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/transformers/utils/hub.py:127: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "x = torch.tensor(features, dtype=torch.float)\n",
    "y = torch.tensor(y, dtype=torch.long)\n",
    "edge_index = torch.tensor(np.array(edges).T, dtype=torch.long)\n",
    "train_mask = torch.tensor(train_mask)\n",
    "test_mask = torch.tensor(test_mask)\n",
    "\n",
    "dataobj = Data(x=x, edge_index=edge_index, y=y)\n",
    "dataobj.train_mask = train_mask\n",
    "dataobj.test_mask = test_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3b1e9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, dataobj):\n",
    "        x, edge_index = dataobj.x, dataobj.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "859e24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GCN(\n",
    "    in_channels=dataobj.num_node_features,\n",
    "    hidden_channels=64,\n",
    "    out_channels=int(y.max().item()) + 1  # number of classes\n",
    ").to(device)\n",
    "\n",
    "dataobj = dataobj.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fbf7249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(dataobj)\n",
    "    loss = criterion(out[dataobj.train_mask], dataobj.y[dataobj.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(mask):\n",
    "    model.eval()\n",
    "    out = model(dataobj)\n",
    "    pred = out[mask].argmax(dim=1)\n",
    "    correct = (pred == dataobj.y[mask]).sum().item()\n",
    "    return correct / mask.sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "da45a43d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010, Loss: 2.6871, Train Acc: 0.2071, Test Acc: 0.2067\n",
      "Epoch 020, Loss: 2.0931, Train Acc: 0.3252, Test Acc: 0.3167\n",
      "Epoch 030, Loss: 1.7199, Train Acc: 0.5367, Test Acc: 0.5289\n",
      "Epoch 040, Loss: 1.4606, Train Acc: 0.6067, Test Acc: 0.5944\n",
      "Epoch 050, Loss: 1.2736, Train Acc: 0.6338, Test Acc: 0.6267\n",
      "Epoch 060, Loss: 1.1390, Train Acc: 0.7210, Test Acc: 0.7067\n",
      "Epoch 070, Loss: 1.0396, Train Acc: 0.7300, Test Acc: 0.7233\n",
      "Epoch 080, Loss: 0.9646, Train Acc: 0.7481, Test Acc: 0.7378\n",
      "Epoch 090, Loss: 0.9064, Train Acc: 0.7586, Test Acc: 0.7489\n",
      "Epoch 100, Loss: 0.8597, Train Acc: 0.7648, Test Acc: 0.7567\n",
      "Epoch 110, Loss: 0.8214, Train Acc: 0.7714, Test Acc: 0.7656\n",
      "Epoch 120, Loss: 0.7890, Train Acc: 0.7729, Test Acc: 0.7678\n",
      "Epoch 130, Loss: 0.7610, Train Acc: 0.7771, Test Acc: 0.7667\n",
      "Epoch 140, Loss: 0.7365, Train Acc: 0.7795, Test Acc: 0.7678\n",
      "Epoch 150, Loss: 0.7148, Train Acc: 0.7800, Test Acc: 0.7667\n",
      "Epoch 160, Loss: 0.6953, Train Acc: 0.7824, Test Acc: 0.7678\n",
      "Epoch 170, Loss: 0.6777, Train Acc: 0.7886, Test Acc: 0.7744\n",
      "Epoch 180, Loss: 0.6616, Train Acc: 0.7948, Test Acc: 0.7789\n",
      "Epoch 190, Loss: 0.6469, Train Acc: 0.7952, Test Acc: 0.7833\n",
      "Epoch 200, Loss: 0.6330, Train Acc: 0.7976, Test Acc: 0.7867\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    if epoch % 10 == 0:\n",
    "        train_acc = test(dataobj.train_mask)\n",
    "        test_acc = test(dataobj.test_mask)\n",
    "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db5e4dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  precision    recall  f1-score   support\n",
      "\n",
      "                          Abu Sayyaf Group (ASG)       0.73      0.97      0.83        31\n",
      "        African National Congress (South Africa)       1.00      0.97      0.98        31\n",
      "                                Al-Qaida in Iraq       0.69      0.73      0.71        30\n",
      "        Al-Qaida in the Arabian Peninsula (AQAP)       0.76      0.86      0.81        29\n",
      "                                      Al-Shabaab       1.00      1.00      1.00        28\n",
      "             Basque Fatherland and Freedom (ETA)       0.97      0.94      0.95        32\n",
      "                                      Boko Haram       0.91      0.95      0.93        22\n",
      "  Communist Party of India - Maoist (CPI-Maoist)       0.68      0.76      0.72        25\n",
      "       Corsican National Liberation Front (FLNC)       0.78      0.88      0.83        33\n",
      "                       Donetsk People's Republic       1.00      0.87      0.93        31\n",
      "Farabundo Marti National Liberation Front (FMLN)       0.81      0.83      0.82        30\n",
      "                               Fulani extremists       0.97      0.94      0.96        34\n",
      "                 Houthi extremists (Ansar Allah)       0.81      0.71      0.76        24\n",
      "                     Irish Republican Army (IRA)       0.81      0.93      0.87        28\n",
      "     Islamic State of Iraq and the Levant (ISIL)       0.61      0.38      0.47        29\n",
      "                  Kurdistan Workers' Party (PKK)       0.63      0.91      0.74        32\n",
      "         Liberation Tigers of Tamil Eelam (LTTE)       0.94      1.00      0.97        32\n",
      "         Manuel Rodriguez Patriotic Front (FPMR)       1.00      1.00      1.00        24\n",
      "                                         Maoists       0.69      0.65      0.67        31\n",
      "                               Muslim extremists       1.00      0.20      0.33        30\n",
      "      National Liberation Army of Colombia (ELN)       0.57      0.80      0.67        30\n",
      "                         New People's Army (NPA)       0.96      0.70      0.81        33\n",
      "               Nicaraguan Democratic Force (FDN)       0.84      0.81      0.83        32\n",
      "                                    Palestinians       0.75      1.00      0.86        30\n",
      "   Revolutionary Armed Forces of Colombia (FARC)       0.74      0.49      0.59        35\n",
      "                               Shining Path (SL)       0.70      0.48      0.57        33\n",
      "                                 Sikh Extremists       0.76      0.87      0.81        30\n",
      "                                         Taliban       0.68      0.94      0.79        32\n",
      "                 Tehrik-i-Taliban Pakistan (TTP)       0.64      0.32      0.43        28\n",
      "       Tupac Amaru Revolutionary Movement (MRTA)       0.59      0.77      0.67        31\n",
      "\n",
      "                                        accuracy                           0.79       900\n",
      "                                       macro avg       0.80      0.79      0.78       900\n",
      "                                    weighted avg       0.80      0.79      0.77       900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report for test set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(dataobj)\n",
    "    pred = out[dataobj.test_mask].argmax(dim=1)\n",
    "    y_true = dataobj.y[dataobj.test_mask].cpu().numpy()\n",
    "    y_pred = pred.cpu().numpy()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true, y_pred, target_names=le.classes_))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
